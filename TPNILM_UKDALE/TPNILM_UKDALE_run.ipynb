{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sivan\\PycharmProjects\\TPNILM\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a small README:\n",
    "# this is runnable from scratch, when having the files:\n",
    "# house_x_labels.dat (x in 1 to 5), the notebook and a kernel of the requirements file.\n",
    "# in cell 3 it is needed to uncomment the download lines, in case UKDATE ds wasn't downloaded yet, as well as uncommenting the unpacking of it, \n",
    "# and uncommenting the zip removal if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "saPKpECRVlln"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import math\n",
    "from collections import defaultdict, OrderedDict\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, matthews_corrcoef\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QPxd9q-PhAXB"
   },
   "source": [
    "# Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_file(url, local_filename):\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()  # Raise an error for bad responses\n",
    "        total_size = int(r.headers.get('content-length', 0))\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            with tqdm(total=total_size, unit='B', unit_scale=True) as bar:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "                    bar.update(len(chunk))\n",
    "\n",
    "# Call the download function\n",
    "# url = \"https://data.ukedc.rl.ac.uk/browse/edc/efficiency/residential/EnergyConsumption/Domestic/UK-DALE-2015/UK-DALE-disaggregated/ukdale.h5.tgz\"\n",
    "# download_file(url, \"ukdale.h5.tgz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "jR0T2s5QNkqv",
    "outputId": "7d50ab1c-fd17-49ee-982b-5199a97f7143"
   },
   "outputs": [],
   "source": [
    "# !tar xvfz ukdale.h5.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "srIUiAAXPRrk"
   },
   "outputs": [],
   "source": [
    "# !rm ukdale.h5.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H9g6B69jPJkz"
   },
   "outputs": [],
   "source": [
    "store = pd.HDFStore('ukdale.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4y3vM6zQz5DC"
   },
   "outputs": [],
   "source": [
    "def resample_meter(store=None, building=1, meter=1, period='1min', cutoff=1000.):\n",
    "    key = '/building{}/elec/meter{}'.format(building,meter)\n",
    "    m = store[key]\n",
    "    v = m.values.flatten()\n",
    "    t = m.index\n",
    "    s = pd.Series(v, index=t).clip(0.,cutoff)\n",
    "    s[s<10.] = 0.\n",
    "    return s.resample('1s').ffill(limit=300).fillna(0.).resample(period).mean().tz_convert('UTC')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_a-pqdClkRmO"
   },
   "outputs": [],
   "source": [
    "def get_series(datastore, house, label, cutoff):\n",
    "    filename = './house_%1d_labels.dat' %house\n",
    "    print(filename)\n",
    "    labels = pd.read_csv(filename, delimiter=' ', header=None, index_col=0).to_dict()[1]\n",
    "    \n",
    "    for i in labels:\n",
    "        if labels[i] == label:\n",
    "            print(i, labels[i])\n",
    "            s = resample_meter(store, house, i, '1min', cutoff)\n",
    "            #s = resample_meter(store, house, i, '6s', cutoff)\n",
    "    \n",
    "    s.index.name = 'to_datetime'\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "6lRVLSIzk6B5",
    "outputId": "bc980e76-1dca-4841-cddd-f10d6ee69d48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./house_1_labels.dat\n",
      "1 aggregate\n",
      "./house_1_labels.dat\n",
      "10 kettle\n",
      "./house_1_labels.dat\n",
      "12 fridge\n",
      "./house_1_labels.dat\n",
      "5 washing_machine\n",
      "./house_1_labels.dat\n",
      "13 microwave\n",
      "./house_1_labels.dat\n",
      "6 dishwasher\n"
     ]
    }
   ],
   "source": [
    "house = 1\n",
    "m = get_series(store, house, 'aggregate', 10000.)\n",
    "m.name = 'aggregate'\n",
    "a1 = get_series(store, house, 'kettle', 3100.)\n",
    "a1.name = 'kettle'\n",
    "a2 = get_series(store, house, 'fridge', 300.)\n",
    "a2.name = 'fridge'\n",
    "a3 = get_series(store, house, 'washing_machine', 2500.)\n",
    "a3.name = 'washing_machine'\n",
    "a4 = get_series(store, house, 'microwave', 3000.)\n",
    "a4.name = 'microwave'\n",
    "a5 = get_series(store, house, 'dishwasher', 2500.)\n",
    "a5.name = 'dish_washer'\n",
    "ds_1 = pd.concat([m, a1, a2, a3, a4, a5], axis=1)\n",
    "ds_1.ffill(inplace=True)\n",
    "\n",
    "ds_1_train = ds_1[pd.to_datetime('2013-04-12 00:00:00+00:00'):pd.to_datetime('2014-12-15 00:00:00+00:00')]\n",
    "ds_1_valid = ds_1[pd.to_datetime('2014-12-15 00:00:00+00:00'):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "5_PW33ZLpwsK",
    "outputId": "776d64c0-fcfa-4637-f983-cf7207bd6ea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./house_2_labels.dat\n",
      "1 aggregate\n",
      "./house_2_labels.dat\n",
      "8 kettle\n",
      "./house_2_labels.dat\n",
      "14 fridge\n",
      "./house_2_labels.dat\n",
      "12 washing_machine\n",
      "./house_2_labels.dat\n",
      "15 microwave\n",
      "./house_2_labels.dat\n",
      "13 dish_washer\n"
     ]
    }
   ],
   "source": [
    "house = 2\n",
    "m = get_series(store, house, 'aggregate', 10000.)\n",
    "m.name = 'aggregate'\n",
    "a1 = get_series(store, house, 'kettle', 3100.)\n",
    "a1.name = 'kettle'\n",
    "a2 = get_series(store, house, 'fridge', 300.)\n",
    "a2.name = 'fridge'\n",
    "a3 = get_series(store, house, 'washing_machine', 2500.)\n",
    "a3.name = 'washing_machine'\n",
    "a4 = get_series(store, house, 'microwave', 3000.)\n",
    "a4.name = 'microwave'\n",
    "a5 = get_series(store, house, 'dish_washer', 2500.)\n",
    "a5.name = 'dish_washer'\n",
    "ds_2 = pd.concat([m, a1, a2, a3, a4, a5], axis=1)\n",
    "ds_2.ffill(inplace=True)\n",
    "\n",
    "ds_2_train = ds_2[pd.to_datetime('2013-05-22 00:00:00+00:00'):pd.to_datetime('2013-10-03 06:16:00+00:00')]\n",
    "ds_2_valid = ds_2[pd.to_datetime('2013-10-03 06:16:00+00:00'):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "WPRtFZqclByE",
    "outputId": "234de859-ec02-433f-8d75-86dbfe448a26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./house_3_labels.dat\n",
      "1 aggregate\n",
      "./house_3_labels.dat\n",
      "2 kettle\n"
     ]
    }
   ],
   "source": [
    "house = 3\n",
    "m = get_series(store, house, 'aggregate', 10000.)\n",
    "m.name = 'aggregate'\n",
    "a1 = get_series(store, house, 'kettle', 3100.)\n",
    "a1.name = 'kettle'\n",
    "a2 = 0.*m\n",
    "a2.name = 'fridge'\n",
    "a3 = 0.*m\n",
    "a3.name = 'washing_machine'\n",
    "a4 = 0.*m\n",
    "a4.name = 'microwave'\n",
    "a5 = 0.*m\n",
    "a5.name = 'dish_washer'\n",
    "ds_3 = pd.concat([m, a1, a2, a3, a4, a5], axis=1)\n",
    "ds_3.ffill(inplace=True)\n",
    "\n",
    "ds_3_train = ds_3[pd.to_datetime('2013-02-27 00:00:00+00:00'):pd.to_datetime('2013-04-01 06:15:00+00:00')]\n",
    "ds_3_valid = ds_3[pd.to_datetime('2013-04-01 06:15:00+00:00'):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "q0xA9KgDqt1q",
    "outputId": "e5eb5263-7e1c-4fbf-c46c-3a2c3e55858a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./house_4_labels.dat\n",
      "1 aggregate\n",
      "./house_4_labels.dat\n",
      "3 kettle_radio\n",
      "./house_4_labels.dat\n",
      "5 freezer\n"
     ]
    }
   ],
   "source": [
    "house = 4\n",
    "m = get_series(store, house, 'aggregate', 10000.)\n",
    "m.name = 'aggregate'\n",
    "a1 = get_series(store, house, 'kettle_radio', 3100.)\n",
    "a1.name = 'kettle'\n",
    "a2 = get_series(store, house, 'freezer', 300.)\n",
    "a2.name = 'fridge'\n",
    "a3 = 0.*m\n",
    "a3.name = 'washing_machine'\n",
    "a4 = 0.*m\n",
    "a4.name = 'microwave'\n",
    "a5 = 0.*m\n",
    "a5.name = 'dish_washer'\n",
    "ds_4 = pd.concat([m, a1, a2, a3, a4, a5], axis=1)\n",
    "ds_4.ffill(inplace=True)\n",
    "\n",
    "ds_4_train = ds_4[pd.to_datetime('2013-03-09 00:00:00+00:00'):pd.to_datetime('2013-09-24 06:15:00+00:00')]\n",
    "ds_4_valid = ds_4[pd.to_datetime('2013-09-24 06:15:00+00:00'):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "-G2EBJcWrM5V",
    "outputId": "088066b8-e349-475e-fdf0-0bd14abcc57c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./house_5_labels.dat\n",
      "1 aggregate\n",
      "./house_5_labels.dat\n",
      "18 kettle\n",
      "./house_5_labels.dat\n",
      "19 fridge_freezer\n",
      "./house_5_labels.dat\n",
      "24 washer_dryer\n",
      "./house_5_labels.dat\n",
      "23 microwave\n",
      "./house_5_labels.dat\n",
      "22 dishwasher\n"
     ]
    }
   ],
   "source": [
    "house = 5\n",
    "m = get_series(store, house, 'aggregate', 10000.)\n",
    "m.name = 'aggregate'\n",
    "a1 = get_series(store, house, 'kettle', 3100.)\n",
    "a1.name = 'kettle'\n",
    "a2 = get_series(store, house, 'fridge_freezer', 300.)\n",
    "a2.name = 'fridge'\n",
    "a3 = get_series(store, house, 'washer_dryer', 2500.)\n",
    "a3.name = 'washing_machine'\n",
    "a4 = get_series(store, house, 'microwave', 3000.)\n",
    "a4.name = 'microwave'\n",
    "a5 = get_series(store, house, 'dishwasher', 2500.)\n",
    "a5.name = 'dish_washer'\n",
    "ds_5 = pd.concat([m, a1, a2, a3, a4, a5], axis=1)\n",
    "ds_5.ffill(inplace=True)\n",
    "\n",
    "ds_5_train = ds_5[pd.to_datetime('2014-06-29 00:00:00+00:00'):pd.to_datetime('2014-09-01 00:00:00+00:00')]\n",
    "ds_5_valid = ds_5[pd.to_datetime('2014-09-01 00:00:00+00:00'):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggregate</th>\n",
       "      <th>kettle</th>\n",
       "      <th>fridge</th>\n",
       "      <th>washing_machine</th>\n",
       "      <th>microwave</th>\n",
       "      <th>dish_washer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-06-29 16:23:00+00:00</th>\n",
       "      <td>769.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.800003</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-29 16:24:00+00:00</th>\n",
       "      <td>1026.633301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.300003</td>\n",
       "      <td>389.633331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-29 16:25:00+00:00</th>\n",
       "      <td>2263.383301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>1312.466675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-29 16:26:00+00:00</th>\n",
       "      <td>957.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.500000</td>\n",
       "      <td>235.699997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-29 16:27:00+00:00</th>\n",
       "      <td>1905.300049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.300003</td>\n",
       "      <td>1058.266724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-31 23:56:00+00:00</th>\n",
       "      <td>490.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>50.700001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-31 23:57:00+00:00</th>\n",
       "      <td>487.133331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>50.400002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-31 23:58:00+00:00</th>\n",
       "      <td>487.399994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>50.299999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-31 23:59:00+00:00</th>\n",
       "      <td>488.399994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>50.299999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-01 00:00:00+00:00</th>\n",
       "      <td>491.483337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91178 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             aggregate  kettle      fridge  washing_machine  \\\n",
       "to_datetime                                                                   \n",
       "2014-06-29 16:23:00+00:00   769.000000     0.0  106.800003       225.000000   \n",
       "2014-06-29 16:24:00+00:00  1026.633301     0.0  106.300003       389.633331   \n",
       "2014-06-29 16:25:00+00:00  2263.383301     0.0  106.000000      1312.466675   \n",
       "2014-06-29 16:26:00+00:00   957.500000     0.0  106.500000       235.699997   \n",
       "2014-06-29 16:27:00+00:00  1905.300049     0.0  105.300003      1058.266724   \n",
       "...                                ...     ...         ...              ...   \n",
       "2014-08-31 23:56:00+00:00   490.000000     0.0    0.000000        15.000000   \n",
       "2014-08-31 23:57:00+00:00   487.133331     0.0    0.000000        14.800000   \n",
       "2014-08-31 23:58:00+00:00   487.399994     0.0    0.000000        14.800000   \n",
       "2014-08-31 23:59:00+00:00   488.399994     0.0    0.000000        15.000000   \n",
       "2014-09-01 00:00:00+00:00   491.483337     0.0    0.000000        15.000000   \n",
       "\n",
       "                           microwave  dish_washer  \n",
       "to_datetime                                        \n",
       "2014-06-29 16:23:00+00:00   0.000000          0.0  \n",
       "2014-06-29 16:24:00+00:00   0.000000          0.0  \n",
       "2014-06-29 16:25:00+00:00   0.000000          0.0  \n",
       "2014-06-29 16:26:00+00:00   0.000000          0.0  \n",
       "2014-06-29 16:27:00+00:00   0.000000          0.0  \n",
       "...                              ...          ...  \n",
       "2014-08-31 23:56:00+00:00  50.700001          0.0  \n",
       "2014-08-31 23:57:00+00:00  50.400002          0.0  \n",
       "2014-08-31 23:58:00+00:00  50.299999          0.0  \n",
       "2014-08-31 23:59:00+00:00  50.299999          0.0  \n",
       "2014-09-01 00:00:00+00:00  50.000000          0.0  \n",
       "\n",
       "[91178 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_5_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "69C1JT0kdJ_W"
   },
   "outputs": [],
   "source": [
    "ds_1_train.reset_index().to_feather('./UKDALE_1_train.feather')\n",
    "ds_2_train.reset_index().to_feather('./UKDALE_2_train.feather')\n",
    "ds_3_train.reset_index().to_feather('./UKDALE_3_train.feather')\n",
    "ds_4_train.reset_index().to_feather('./UKDALE_4_train.feather')\n",
    "ds_5_train.reset_index().to_feather('./UKDALE_5_train.feather')\n",
    "\n",
    "ds_1_valid.reset_index().to_feather('./UKDALE_1_valid.feather')\n",
    "ds_2_valid.reset_index().to_feather('./UKDALE_2_valid.feather')\n",
    "ds_3_valid.reset_index().to_feather('./UKDALE_3_valid.feather')\n",
    "ds_4_valid.reset_index().to_feather('./UKDALE_4_valid.feather')\n",
    "ds_5_valid.reset_index().to_feather('./UKDALE_5_valid.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PvY0BjXDdKXR"
   },
   "source": [
    "# Read the feather dataframe resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I5vzLJT4LwVl"
   },
   "outputs": [],
   "source": [
    "def get_status(app, threshold, min_off, min_on):\n",
    "    condition = app > threshold\n",
    "    # Find the indicies of changes in \"condition\"\n",
    "    d = np.diff(condition)\n",
    "    idx, = d.nonzero() \n",
    "\n",
    "    # We need to start things after the change in \"condition\". Therefore, \n",
    "    # we'll shift the index by 1 to the right.\n",
    "    idx += 1\n",
    "\n",
    "    if condition[0]:\n",
    "        # If the start of condition is True prepend a 0\n",
    "        idx = np.r_[0, idx]\n",
    "\n",
    "    if condition[-1]:\n",
    "        # If the end of condition is True, append the length of the array\n",
    "        idx = np.r_[idx, condition.size] # Edit\n",
    "\n",
    "    # Reshape the result into two columns\n",
    "    idx.shape = (-1,2)\n",
    "    on_events = idx[:,0].copy()\n",
    "    off_events = idx[:,1].copy()\n",
    "    assert len(on_events) == len(off_events)\n",
    "\n",
    "    if len(on_events) > 0:\n",
    "        off_duration = on_events[1:] - off_events[:-1]\n",
    "        off_duration = np.insert(off_duration, 0, 1000.)\n",
    "        on_events = on_events[off_duration > min_off]\n",
    "        off_events = off_events[np.roll(off_duration, -1) > min_off]\n",
    "        assert len(on_events) == len(off_events)\n",
    "\n",
    "        on_duration = off_events - on_events\n",
    "        on_events = on_events[on_duration > min_on]\n",
    "        off_events = off_events[on_duration > min_on]\n",
    "\n",
    "    s = app.copy()\n",
    "    #s.iloc[:] = 0.\n",
    "    s[:] = 0.\n",
    "\n",
    "    for on, off in zip(on_events, off_events):\n",
    "        #s.iloc[on:off] = 1.\n",
    "        s[on:off] = 1.\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5iR9d91y1ktT"
   },
   "outputs": [],
   "source": [
    "class Power(data.Dataset):\n",
    "    def __init__(self, meter=None, appliance=None, status=None, \n",
    "                 length=256, border=680, max_power=1., train=False):\n",
    "        self.length = length\n",
    "        self.border = border\n",
    "        self.max_power = max_power\n",
    "        self.train = train\n",
    "\n",
    "        self.meter = meter.copy()/self.max_power\n",
    "        self.appliance = appliance.copy()/self.max_power\n",
    "        self.status = status.copy()\n",
    "\n",
    "        self.epochs = (len(self.meter) - 2*self.border) // self.length\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        i = index * self.length + self.border\n",
    "        if self.train:\n",
    "            i = np.random.randint(self.border, len(self.meter) - self.length - self.border)\n",
    "\n",
    "        x = self.meter.iloc[i-self.border:i+self.length+self.border].values.astype('float32')\n",
    "        y = self.appliance.iloc[i:i+self.length].values.astype('float32')\n",
    "        s = self.status.iloc[i:i+self.length].values.astype('float32')\n",
    "        x -= x.mean()\n",
    "        \n",
    "        return x, y, s\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mirkSD9a1qTQ",
    "outputId": "df7353f4-93f8-4583-da76-3d999bb2d248"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 480])\n",
      "327619\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_features=3, out_features=1, kernel_size=3, padding=1, stride=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_features, out_features, kernel_size=kernel_size, padding=padding, stride=stride, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(out_features)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #return self.bn(F.relu(self.conv(x)))\n",
    "        return self.drop(self.bn(F.relu(self.conv(x))))\n",
    "\n",
    "class TemporalPooling(nn.Module):\n",
    "    def __init__(self, in_features=3, out_features=1, kernel_size=2):\n",
    "        super(TemporalPooling, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.pool = nn.AvgPool1d(kernel_size=self.kernel_size, stride=self.kernel_size)\n",
    "        self.conv = nn.Conv1d(in_features, out_features, kernel_size=1, padding=0)\n",
    "        #self.upsample = nn.Upsample( scale_factor=kernel_size, mode='linear', align_corners=True)\n",
    "        self.bn = nn.BatchNorm1d(out_features)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(F.relu(x))\n",
    "        #return self.upsample(x)\n",
    "        #return self.drop(self.upsample(x))\n",
    "        return self.drop(F.interpolate(x, scale_factor=self.kernel_size, mode='linear', align_corners=True))\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_features=3, out_features=1, kernel_size=2, stride=2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.conv = nn.ConvTranspose1d(in_features, out_features, kernel_size=kernel_size, stride=stride, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.conv(x))\n",
    "\n",
    "class PTPNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
    "        super(PTPNet, self).__init__()\n",
    "        p = 2\n",
    "        k = 1\n",
    "        features = init_features\n",
    "        self.encoder1 = Encoder(in_channels, features, kernel_size=3, padding=0)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=p, stride=p)\n",
    "        self.encoder2 = Encoder(features * 1**k, features * 2**k, kernel_size=3, padding=0)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=p, stride=p)\n",
    "        self.encoder3 = Encoder(features * 2**k, features * 4**k, kernel_size=3, padding=0)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=p, stride=p)\n",
    "        self.encoder4 = Encoder(features * 4**k, features * 8**k, kernel_size=3, padding=0)\n",
    "        \n",
    "        self.tpool1 = TemporalPooling(features*8**k, features*2**k, kernel_size=5)\n",
    "        self.tpool2 = TemporalPooling(features*8**k, features*2**k, kernel_size=10)\n",
    "        self.tpool3 = TemporalPooling(features*8**k, features*2**k, kernel_size=20)\n",
    "        self.tpool4 = TemporalPooling(features*8**k, features*2**k, kernel_size=30)\n",
    "\n",
    "        self.decoder = Decoder(2*features * 8**k, features * 1**k, kernel_size=p**3, stride=p**3)\n",
    "\n",
    "        self.activation = nn.Conv1d(features * 1**k, out_channels, kernel_size=1, padding=0)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        tp1 = self.tpool1(enc4)\n",
    "        tp2 = self.tpool2(enc4)\n",
    "        tp3 = self.tpool3(enc4)\n",
    "        tp4 = self.tpool4(enc4)\n",
    "\n",
    "        dec = self.decoder(torch.cat([enc4, tp1, tp2, tp3, tp4], dim=1))\n",
    "\n",
    "        act = self.activation(dec)\n",
    "        return act\n",
    "\n",
    "x = torch.randn(32,1,60*8+2*16)\n",
    "model = PTPNet(1,3,32)\n",
    "print(model(x).shape)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fMsGSOln1wS3"
   },
   "outputs": [],
   "source": [
    "def train_model(model, batch_size, n_epochs, filename):\n",
    "    \n",
    "    # to track the training loss as the model trains\n",
    "    train_losses = []\n",
    "    # to track the validation loss as the model trains\n",
    "    valid_losses = []\n",
    "    # to track the test loss as the model trains\n",
    "    test_losses = []\n",
    "    # to track the unseen test loss as the model trains\n",
    "    unseen_test_losses = []\n",
    "    # to track the average training loss per epoch as the model trains\n",
    "    avg_train_losses = []\n",
    "    # to track the average validation loss per epoch as the model trains\n",
    "    avg_valid_losses = [] \n",
    "    # to track the average test loss per epoch as the model trains\n",
    "    avg_test_losses = [] \n",
    "    # to track the average unseen test loss per epoch as the model trains\n",
    "    avg_unseen_test_losses = []\n",
    "    \n",
    "    min_loss = np.inf\n",
    "    \n",
    "    # initialize the early_stopping object\n",
    "    #patience = 10\n",
    "    #early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train() # prep model for training\n",
    "        for batch, (data, target_power, target_status) in enumerate(train_loader, 1):\n",
    "            data = data.unsqueeze(1).to(device)\n",
    "            target_power = target_power.to(device)\n",
    "            target_status = target_status.to(device)\n",
    "            \n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output_status = model(data).permute(0,2,1)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output_status, target_status)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # record training loss\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval() # prep model for evaluation\n",
    "        for data, target_power, target_status in valid_loader:\n",
    "            data = data.unsqueeze(1).to(device)\n",
    "            target_power = target_power.to(device)\n",
    "            target_status = target_status.to(device)\n",
    "            \n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output_status = model(data).permute(0,2,1)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output_status, target_status)\n",
    "            # record validation loss\n",
    "            valid_losses.append(loss.item())\n",
    "\n",
    "        ##################    \n",
    "        # test the model #\n",
    "        ##################\n",
    "        \n",
    "        # seen data\n",
    "        model.eval() # prep model for evaluation\n",
    "        for data, target_power, target_status in test_loader:\n",
    "            data = data.unsqueeze(1).to(device)\n",
    "            target_power = target_power.to(device)\n",
    "            target_status = target_status.to(device)\n",
    "            \n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output_status = model(data).permute(0,2,1)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output_status, target_status)\n",
    "            # record validation loss\n",
    "            test_losses.append(loss.item())\n",
    "\n",
    "        # unseen data\n",
    "        for data, target_power, target_status in unseen_test_loader:\n",
    "            data = data.unsqueeze(1).to(device)\n",
    "            target_power = target_power.to(device)\n",
    "            target_status = target_status.to(device)\n",
    "            \n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output_status = model(data).permute(0,2,1)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output_status, target_status)\n",
    "            # record validation loss\n",
    "            unseen_test_losses.append(loss.item())\n",
    "\n",
    "        # print training/validation statistics \n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        test_loss = np.average(test_losses)\n",
    "        unseen_test_loss = np.average(unseen_test_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        avg_test_losses.append(test_loss)\n",
    "        avg_unseen_test_losses.append(unseen_test_loss)\n",
    "        \n",
    "        epoch_len = len(str(n_epochs))\n",
    "        \n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'valid_loss: {valid_loss:.5f} ' +\n",
    "                     f'test_loss: {test_loss:.5f} ' +\n",
    "                    f'unseen_test_loss: {unseen_test_loss:.5f} ')\n",
    "        \n",
    "        print(print_msg)\n",
    "        \n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        test_losses = []\n",
    "        unseen_test_losses = []\n",
    "        \n",
    "        # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        #early_stopping(valid_loss, model)\n",
    "        #if (early_stopping.early_stop and (epoch > 80)):\n",
    "        #    break\n",
    "        \n",
    "        if valid_loss < min_loss:\n",
    "            print(f'Validation loss decreased ({min_loss:.6f} --> {valid_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), filename)\n",
    "            min_loss = valid_loss\n",
    "        \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load(filename, weights_only=True))\n",
    "    \n",
    "    return  model, avg_train_losses, avg_valid_losses, avg_test_losses, avg_unseen_test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pP9W8d_K12mm"
   },
   "outputs": [],
   "source": [
    "def evaluate_activation(model, loader, a):\n",
    "    x_true = []\n",
    "    s_true = []\n",
    "    p_true = []\n",
    "    s_hat = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, p, s in loader:\n",
    "            x = x.unsqueeze(1).to(device)\n",
    "            p = p.permute(0,2,1)[:,a,:]\n",
    "            s = s.permute(0,2,1)[:,a,:]\n",
    "            \n",
    "            sh = model(x)\n",
    "            sh = torch.sigmoid(sh[:,a,:])\n",
    "            \n",
    "            s_hat.append(sh.contiguous().view(-1).detach().cpu().numpy())\n",
    "            \n",
    "            x_true.append(x[:,:,BORDER:-BORDER].contiguous().view(-1).detach().cpu().numpy())\n",
    "            s_true.append(s.contiguous().view(-1).detach().cpu().numpy())\n",
    "            p_true.append(p.contiguous().view(-1).detach().cpu().numpy())\n",
    "    x_true = np.hstack(x_true)\n",
    "    s_true = np.hstack(s_true)\n",
    "    p_true = np.hstack(p_true)\n",
    "    s_hat = np.hstack(s_hat)\n",
    "\n",
    "    return x_true, p_true, s_true, s_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PSypXakc14qb"
   },
   "outputs": [],
   "source": [
    "APPLIANCE = ['fridge', 'dish_washer', 'washing_machine']\n",
    "THRESHOLD = [50., 10., 20.]\n",
    "MIN_ON = [1., 30., 30.]\n",
    "MIN_OFF = [1., 30., 3.]\n",
    "\n",
    "METER = 'aggregate'\n",
    "SEQ_LEN = 60*8\n",
    "BORDER = 16\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "MAX_POWER = 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mO2wSprQfV6x",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[0]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[-1]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[0]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[-1]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[0]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[-1]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[0]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[-1]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[0]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[-1]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[0]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[-1]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[0]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[-1]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[0]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[-1]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[0]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[-1]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[0]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[-1]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[0]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[-1]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[0]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[-1]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[0]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[-1]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[0]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[-1]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[0]:\n",
      "C:\\Users\\sivan\\AppData\\Local\\Temp\\ipykernel_26068\\873049420.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if condition[-1]:\n"
     ]
    }
   ],
   "source": [
    "ds_meter = []\n",
    "ds_appliance = []\n",
    "ds_status = []\n",
    "for i in range(5):\n",
    "    ds = pd.read_feather('./UKDALE_%d_train.feather' %(i+1))\n",
    "    ds.set_index('to_datetime', inplace=True)\n",
    "    \n",
    "    meter = ds[METER]\n",
    "    appliances = ds[APPLIANCE]\n",
    "    \n",
    "    status = pd.DataFrame()\n",
    "    for a in range(len(APPLIANCE)):\n",
    "        status = pd.concat([status, get_status(ds[APPLIANCE[a]], THRESHOLD[a], MIN_OFF[a], MIN_ON[a])], axis=1)\n",
    "    \n",
    "    ds_meter.append(meter)\n",
    "    ds_appliance.append(appliances)\n",
    "    ds_status.append(status)\n",
    "\n",
    "ds_len = [len(ds_meter[i]) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "sGfWAsgWbVtt",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2c141854-5a34-469f-e034-c5f535f83c52",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fridge             3525\n",
       "dish_washer          98\n",
       "washing_machine      54\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ds_status[1].diff()==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "Tq5YJh7lzqvS",
    "outputId": "494fd4da-e7ad-485e-9da1-4ffee3d198a0",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fridge</th>\n",
       "      <th>dish_washer</th>\n",
       "      <th>washing_machine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>193337.000000</td>\n",
       "      <td>193337.000000</td>\n",
       "      <td>193337.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.377920</td>\n",
       "      <td>0.028918</td>\n",
       "      <td>0.011317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.484869</td>\n",
       "      <td>0.167578</td>\n",
       "      <td>0.105778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              fridge    dish_washer  washing_machine\n",
       "count  193337.000000  193337.000000    193337.000000\n",
       "mean        0.377920       0.028918         0.011317\n",
       "std         0.484869       0.167578         0.105778\n",
       "min         0.000000       0.000000         0.000000\n",
       "25%         0.000000       0.000000         0.000000\n",
       "50%         0.000000       0.000000         0.000000\n",
       "75%         1.000000       0.000000         0.000000\n",
       "max         1.000000       1.000000         1.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_status[1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fridge</th>\n",
       "      <th>dish_washer</th>\n",
       "      <th>washing_machine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-05-22 00:00:00+00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-22 00:01:00+00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-22 00:02:00+00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-22 00:03:00+00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-22 00:04:00+00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03 06:12:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03 06:13:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03 06:14:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03 06:15:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03 06:16:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193337 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           fridge  dish_washer  washing_machine\n",
       "2013-05-22 00:00:00+00:00     1.0          0.0              0.0\n",
       "2013-05-22 00:01:00+00:00     1.0          0.0              0.0\n",
       "2013-05-22 00:02:00+00:00     1.0          0.0              0.0\n",
       "2013-05-22 00:03:00+00:00     1.0          0.0              0.0\n",
       "2013-05-22 00:04:00+00:00     1.0          0.0              0.0\n",
       "...                           ...          ...              ...\n",
       "2013-10-03 06:12:00+00:00     0.0          0.0              0.0\n",
       "2013-10-03 06:13:00+00:00     0.0          0.0              0.0\n",
       "2013-10-03 06:14:00+00:00     0.0          0.0              0.0\n",
       "2013-10-03 06:15:00+00:00     0.0          0.0              0.0\n",
       "2013-10-03 06:16:00+00:00     0.0          0.0              0.0\n",
       "\n",
       "[193337 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_status[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iLZ7PmzG7jHS"
   },
   "outputs": [],
   "source": [
    "ds_house_train = [Power(ds_meter[i][:int(0.8*ds_len[i])], \n",
    "                        ds_appliance[i][:int(0.8*ds_len[i])], \n",
    "                        ds_status[i][:int(0.8*ds_len[i])], \n",
    "                        SEQ_LEN, BORDER, MAX_POWER, True) for i in range(5+0)]\n",
    "\n",
    "ds_house_valid = [Power(ds_meter[i][int(0.8*ds_len[i]):int(0.9*ds_len[i])], \n",
    "                        ds_appliance[i][int(0.8*ds_len[i]):int(0.9*ds_len[i])],\n",
    "                        ds_status[i][int(0.8*ds_len[i]):int(0.9*ds_len[i])], \n",
    "                        SEQ_LEN, BORDER, MAX_POWER, False) for i in range(5+0)]\n",
    "\n",
    "ds_house_test  = [Power(ds_meter[i][int(0.9*ds_len[i]):], \n",
    "                        ds_appliance[i][int(0.9*ds_len[i]):],\n",
    "                        ds_status[i][int(0.9*ds_len[i]):], \n",
    "                        SEQ_LEN, BORDER, MAX_POWER, False) for i in range(5+0)]\n",
    "\n",
    "ds_house_total  = [Power(ds_meter[i], ds_appliance[i], ds_status[i], \n",
    "                         SEQ_LEN, BORDER, MAX_POWER, False) for i in range(5+0)]\n",
    "\n",
    "ds_train_seen = torch.utils.data.ConcatDataset([ds_house_train[0], \n",
    "                                                ds_house_train[1], \n",
    "                                                #ds_house_train[2], \n",
    "                                                #ds_house_train[3],\n",
    "                                                #ds_house_train[4]\n",
    "                                                ])\n",
    "ds_valid_seen = torch.utils.data.ConcatDataset([ds_house_valid[0], \n",
    "                                                ds_house_valid[1], \n",
    "                                                #ds_house_valid[2], \n",
    "                                                #ds_house_valid[3], \n",
    "                                                #ds_house_valid[4]\n",
    "                                                ])\n",
    "\n",
    "ds_test_seen = torch.utils.data.ConcatDataset([ds_house_test[0], \n",
    "                                                ds_house_test[1], \n",
    "                                                #ds_house_valid[2], \n",
    "                                                #ds_house_valid[3], \n",
    "                                                #ds_house_valid[4]\n",
    "                                                ])\n",
    "\n",
    "dl_train_seen = DataLoader(dataset = ds_train_seen, batch_size = BATCH_SIZE, shuffle=True)\n",
    "dl_valid_seen = DataLoader(dataset = ds_valid_seen, batch_size = BATCH_SIZE, shuffle=False)\n",
    "dl_test_seen = DataLoader(dataset = ds_test_seen, batch_size = BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ds_train_unseen = torch.utils.data.ConcatDataset([#ds_house_train[0], \n",
    "#                                                   #ds_house_train[1], \n",
    "#                                                   #ds_house_train[2], \n",
    "#                                                   #ds_house_train[3], \n",
    "#                                                   #ds_house_train[4]\n",
    "#                                                   ])\n",
    "# ds_valid_unseen = torch.utils.data.ConcatDataset([#ds_house_valid[0], \n",
    "#                                                   #ds_house_valid[1], \n",
    "#                                                   #ds_house_valid[2], \n",
    "#                                                   #ds_house_valid[3], \n",
    "#                                                   #ds_house_valid[4]\n",
    "#                                                   ])\n",
    "# dl_train_unseen = DataLoader(dataset = ds_train_unseen, batch_size = BATCH_SIZE, shuffle=True)\n",
    "# dl_valid_unseen = DataLoader(dataset = ds_valid_unseen, batch_size = BATCH_SIZE, shuffle=False)\n",
    "dl_test_unseen = DataLoader(dataset = ds_house_total[4], batch_size = BATCH_SIZE, shuffle=False)\n",
    "\n",
    "dl_house_test = [DataLoader(dataset = ds_house_test[i], batch_size = 1, shuffle=False) for i in range(5)]\n",
    "dl_house_valid = [DataLoader(dataset = ds_house_valid[i], batch_size = 1, shuffle=False) for i in range(5)]\n",
    "dl_house_total = [DataLoader(dataset = ds_house_total[i], batch_size = 1, shuffle=False) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QC-IwqzoL2D5"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(dl_house_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x17c16b84700>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_house_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "colab_type": "code",
    "id": "rB6NlwrYYE3D",
    "outputId": "1a9d8d38-b2b9-45cd-f1fd-0b0604f464a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 1.5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "#x, y, s = next(dataiter)\n",
    "a = 1\n",
    "for i in range(100):\n",
    "    x, y, s = next(dataiter)  # Use next(dataiter) instead of dataiter.next()\n",
    "    if y[0, :, a].sum() > 0:\n",
    "        break\n",
    "    if s[0, :, a].sum() > 0:\n",
    "        break\n",
    "\n",
    " x = self.meter.iloc[i-self.border:i+self.length+self.border].values.astype('float32')\n",
    "        y = self.appliance.iloc[i:i+self.length].values.astype('float32')\n",
    "        s = self.st\n",
    "\n",
    "\n",
    "plt.plot(np.arange(-BORDER, SEQ_LEN + BORDER), x[0, :].detach().numpy(), 'k-', label='meter') \n",
    "plt.plot(y[0, :, a].detach().numpy(), label='appliance')\n",
    "plt.plot(s[0, :, a].detach().numpy(), label='stastus')\n",
    "plt.ylim([-0.5, 1.5])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL 0\n",
      "[ 1/50] train_loss: 0.54833 valid_loss: 0.43050 test_loss: 0.43412 unseen_test_loss: 0.41641 \n",
      "Validation loss decreased (inf --> 0.430502).  Saving model ...\n",
      "[ 2/50] train_loss: 0.36809 valid_loss: 0.31778 test_loss: 0.32798 unseen_test_loss: 0.31708 \n",
      "Validation loss decreased (0.430502 --> 0.317780).  Saving model ...\n",
      "[ 3/50] train_loss: 0.28747 valid_loss: 0.26076 test_loss: 0.27581 unseen_test_loss: 0.27469 \n",
      "Validation loss decreased (0.317780 --> 0.260760).  Saving model ...\n",
      "[ 4/50] train_loss: 0.24175 valid_loss: 0.22219 test_loss: 0.23893 unseen_test_loss: 0.25065 \n",
      "Validation loss decreased (0.260760 --> 0.222195).  Saving model ...\n",
      "[ 5/50] train_loss: 0.20887 valid_loss: 0.19834 test_loss: 0.21442 unseen_test_loss: 0.23383 \n",
      "Validation loss decreased (0.222195 --> 0.198338).  Saving model ...\n",
      "[ 6/50] train_loss: 0.19055 valid_loss: 0.18034 test_loss: 0.19629 unseen_test_loss: 0.22155 \n",
      "Validation loss decreased (0.198338 --> 0.180338).  Saving model ...\n",
      "[ 7/50] train_loss: 0.17672 valid_loss: 0.16942 test_loss: 0.18373 unseen_test_loss: 0.20699 \n",
      "Validation loss decreased (0.180338 --> 0.169420).  Saving model ...\n",
      "[ 8/50] train_loss: 0.16816 valid_loss: 0.16216 test_loss: 0.17582 unseen_test_loss: 0.20529 \n",
      "Validation loss decreased (0.169420 --> 0.162161).  Saving model ...\n",
      "[ 9/50] train_loss: 0.16148 valid_loss: 0.15686 test_loss: 0.17273 unseen_test_loss: 0.20131 \n",
      "Validation loss decreased (0.162161 --> 0.156863).  Saving model ...\n",
      "[10/50] train_loss: 0.15428 valid_loss: 0.14873 test_loss: 0.16284 unseen_test_loss: 0.19203 \n",
      "Validation loss decreased (0.156863 --> 0.148726).  Saving model ...\n",
      "[11/50] train_loss: 0.14899 valid_loss: 0.14715 test_loss: 0.16065 unseen_test_loss: 0.19078 \n",
      "Validation loss decreased (0.148726 --> 0.147147).  Saving model ...\n",
      "[12/50] train_loss: 0.14514 valid_loss: 0.14240 test_loss: 0.15687 unseen_test_loss: 0.18678 \n",
      "Validation loss decreased (0.147147 --> 0.142396).  Saving model ...\n",
      "[13/50] train_loss: 0.14391 valid_loss: 0.14065 test_loss: 0.15453 unseen_test_loss: 0.18893 \n",
      "Validation loss decreased (0.142396 --> 0.140652).  Saving model ...\n",
      "[14/50] train_loss: 0.14034 valid_loss: 0.13565 test_loss: 0.14857 unseen_test_loss: 0.18439 \n",
      "Validation loss decreased (0.140652 --> 0.135648).  Saving model ...\n",
      "[15/50] train_loss: 0.13888 valid_loss: 0.13105 test_loss: 0.14511 unseen_test_loss: 0.17447 \n",
      "Validation loss decreased (0.135648 --> 0.131048).  Saving model ...\n",
      "[16/50] train_loss: 0.13313 valid_loss: 0.13011 test_loss: 0.14402 unseen_test_loss: 0.17695 \n",
      "Validation loss decreased (0.131048 --> 0.130109).  Saving model ...\n",
      "[17/50] train_loss: 0.13329 valid_loss: 0.12709 test_loss: 0.14052 unseen_test_loss: 0.17371 \n",
      "Validation loss decreased (0.130109 --> 0.127089).  Saving model ...\n",
      "[18/50] train_loss: 0.12979 valid_loss: 0.12735 test_loss: 0.14054 unseen_test_loss: 0.17572 \n",
      "[19/50] train_loss: 0.12904 valid_loss: 0.12805 test_loss: 0.14130 unseen_test_loss: 0.17858 \n",
      "[20/50] train_loss: 0.12732 valid_loss: 0.12366 test_loss: 0.13646 unseen_test_loss: 0.17475 \n",
      "Validation loss decreased (0.127089 --> 0.123658).  Saving model ...\n",
      "[21/50] train_loss: 0.12515 valid_loss: 0.12059 test_loss: 0.13369 unseen_test_loss: 0.17343 \n",
      "Validation loss decreased (0.123658 --> 0.120587).  Saving model ...\n",
      "[22/50] train_loss: 0.12571 valid_loss: 0.12242 test_loss: 0.13547 unseen_test_loss: 0.17171 \n",
      "[23/50] train_loss: 0.12179 valid_loss: 0.12000 test_loss: 0.13192 unseen_test_loss: 0.16783 \n",
      "Validation loss decreased (0.120587 --> 0.120000).  Saving model ...\n",
      "[24/50] train_loss: 0.12054 valid_loss: 0.11866 test_loss: 0.13041 unseen_test_loss: 0.17634 \n",
      "Validation loss decreased (0.120000 --> 0.118663).  Saving model ...\n",
      "[25/50] train_loss: 0.11575 valid_loss: 0.11517 test_loss: 0.12864 unseen_test_loss: 0.17078 \n",
      "Validation loss decreased (0.118663 --> 0.115168).  Saving model ...\n",
      "[26/50] train_loss: 0.11774 valid_loss: 0.11660 test_loss: 0.12874 unseen_test_loss: 0.17113 \n",
      "[27/50] train_loss: 0.11525 valid_loss: 0.11588 test_loss: 0.12838 unseen_test_loss: 0.16522 \n",
      "[28/50] train_loss: 0.11557 valid_loss: 0.11463 test_loss: 0.12724 unseen_test_loss: 0.16852 \n",
      "Validation loss decreased (0.115168 --> 0.114626).  Saving model ...\n",
      "[29/50] train_loss: 0.11443 valid_loss: 0.11311 test_loss: 0.12606 unseen_test_loss: 0.17023 \n",
      "Validation loss decreased (0.114626 --> 0.113110).  Saving model ...\n",
      "[30/50] train_loss: 0.11022 valid_loss: 0.11279 test_loss: 0.12545 unseen_test_loss: 0.16413 \n",
      "Validation loss decreased (0.113110 --> 0.112787).  Saving model ...\n",
      "[31/50] train_loss: 0.11158 valid_loss: 0.11256 test_loss: 0.12630 unseen_test_loss: 0.16651 \n",
      "Validation loss decreased (0.112787 --> 0.112562).  Saving model ...\n",
      "[32/50] train_loss: 0.11187 valid_loss: 0.11305 test_loss: 0.12472 unseen_test_loss: 0.17080 \n",
      "[33/50] train_loss: 0.11122 valid_loss: 0.11036 test_loss: 0.12274 unseen_test_loss: 0.16772 \n",
      "Validation loss decreased (0.112562 --> 0.110355).  Saving model ...\n",
      "[34/50] train_loss: 0.10958 valid_loss: 0.11245 test_loss: 0.12250 unseen_test_loss: 0.16969 \n",
      "[35/50] train_loss: 0.10846 valid_loss: 0.11200 test_loss: 0.12273 unseen_test_loss: 0.17287 \n",
      "[36/50] train_loss: 0.10996 valid_loss: 0.10817 test_loss: 0.12126 unseen_test_loss: 0.16244 \n",
      "Validation loss decreased (0.110355 --> 0.108167).  Saving model ...\n",
      "[37/50] train_loss: 0.10637 valid_loss: 0.10736 test_loss: 0.12154 unseen_test_loss: 0.17493 \n",
      "Validation loss decreased (0.108167 --> 0.107365).  Saving model ...\n",
      "[38/50] train_loss: 0.10556 valid_loss: 0.10925 test_loss: 0.11939 unseen_test_loss: 0.17398 \n",
      "[39/50] train_loss: 0.10373 valid_loss: 0.10890 test_loss: 0.11994 unseen_test_loss: 0.16880 \n",
      "[40/50] train_loss: 0.10429 valid_loss: 0.10777 test_loss: 0.12011 unseen_test_loss: 0.17134 \n",
      "[41/50] train_loss: 0.10429 valid_loss: 0.10565 test_loss: 0.11793 unseen_test_loss: 0.16885 \n",
      "Validation loss decreased (0.107365 --> 0.105649).  Saving model ...\n",
      "[42/50] train_loss: 0.10803 valid_loss: 0.10643 test_loss: 0.11694 unseen_test_loss: 0.17456 \n",
      "[43/50] train_loss: 0.10722 valid_loss: 0.10717 test_loss: 0.11691 unseen_test_loss: 0.17363 \n",
      "[44/50] train_loss: 0.10617 valid_loss: 0.10766 test_loss: 0.11641 unseen_test_loss: 0.17124 \n",
      "[45/50] train_loss: 0.10296 valid_loss: 0.11162 test_loss: 0.11727 unseen_test_loss: 0.17274 \n",
      "[46/50] train_loss: 0.10397 valid_loss: 0.10578 test_loss: 0.11764 unseen_test_loss: 0.17502 \n",
      "[47/50] train_loss: 0.10432 valid_loss: 0.10953 test_loss: 0.11796 unseen_test_loss: 0.18284 \n",
      "[48/50] train_loss: 0.10354 valid_loss: 0.11311 test_loss: 0.11559 unseen_test_loss: 0.17141 \n",
      "[49/50] train_loss: 0.09918 valid_loss: 0.10506 test_loss: 0.11447 unseen_test_loss: 0.17326 \n",
      "Validation loss decreased (0.105649 --> 0.105065).  Saving model ...\n",
      "[50/50] train_loss: 0.10017 valid_loss: 0.10343 test_loss: 0.11300 unseen_test_loss: 0.17040 \n",
      "Validation loss decreased (0.105065 --> 0.103434).  Saving model ...\n",
      "saved results for model UKDALE_seen_0.pth\n",
      "TRAINING MODEL 1\n",
      "[ 1/50] train_loss: 0.55132 valid_loss: 0.43367 test_loss: 0.43411 unseen_test_loss: 0.43827 \n",
      "Validation loss decreased (inf --> 0.433667).  Saving model ...\n",
      "[ 2/50] train_loss: 0.36141 valid_loss: 0.31112 test_loss: 0.32092 unseen_test_loss: 0.31525 \n",
      "Validation loss decreased (0.433667 --> 0.311123).  Saving model ...\n",
      "[ 3/50] train_loss: 0.27869 valid_loss: 0.26152 test_loss: 0.27472 unseen_test_loss: 0.27867 \n",
      "Validation loss decreased (0.311123 --> 0.261522).  Saving model ...\n",
      "[ 4/50] train_loss: 0.23778 valid_loss: 0.22947 test_loss: 0.24180 unseen_test_loss: 0.25300 \n",
      "Validation loss decreased (0.261522 --> 0.229471).  Saving model ...\n",
      "[ 5/50] train_loss: 0.21412 valid_loss: 0.20413 test_loss: 0.21804 unseen_test_loss: 0.23537 \n",
      "Validation loss decreased (0.229471 --> 0.204131).  Saving model ...\n",
      "[ 6/50] train_loss: 0.19230 valid_loss: 0.18926 test_loss: 0.20292 unseen_test_loss: 0.22259 \n",
      "Validation loss decreased (0.204131 --> 0.189260).  Saving model ...\n",
      "[ 7/50] train_loss: 0.18030 valid_loss: 0.17852 test_loss: 0.19009 unseen_test_loss: 0.21882 \n",
      "Validation loss decreased (0.189260 --> 0.178521).  Saving model ...\n",
      "[ 8/50] train_loss: 0.17203 valid_loss: 0.16781 test_loss: 0.17939 unseen_test_loss: 0.20948 \n",
      "Validation loss decreased (0.178521 --> 0.167810).  Saving model ...\n",
      "[ 9/50] train_loss: 0.16272 valid_loss: 0.16171 test_loss: 0.17361 unseen_test_loss: 0.20832 \n",
      "Validation loss decreased (0.167810 --> 0.161714).  Saving model ...\n",
      "[10/50] train_loss: 0.15215 valid_loss: 0.15321 test_loss: 0.16516 unseen_test_loss: 0.19831 \n",
      "Validation loss decreased (0.161714 --> 0.153211).  Saving model ...\n",
      "[11/50] train_loss: 0.15228 valid_loss: 0.15045 test_loss: 0.16290 unseen_test_loss: 0.20022 \n",
      "Validation loss decreased (0.153211 --> 0.150447).  Saving model ...\n",
      "[12/50] train_loss: 0.14784 valid_loss: 0.14547 test_loss: 0.15793 unseen_test_loss: 0.19216 \n",
      "Validation loss decreased (0.150447 --> 0.145469).  Saving model ...\n",
      "[13/50] train_loss: 0.14674 valid_loss: 0.14264 test_loss: 0.15593 unseen_test_loss: 0.19506 \n",
      "Validation loss decreased (0.145469 --> 0.142641).  Saving model ...\n",
      "[14/50] train_loss: 0.14120 valid_loss: 0.13924 test_loss: 0.15088 unseen_test_loss: 0.18434 \n",
      "Validation loss decreased (0.142641 --> 0.139237).  Saving model ...\n",
      "[15/50] train_loss: 0.14376 valid_loss: 0.13641 test_loss: 0.14917 unseen_test_loss: 0.18686 \n",
      "Validation loss decreased (0.139237 --> 0.136414).  Saving model ...\n",
      "[16/50] train_loss: 0.13312 valid_loss: 0.13531 test_loss: 0.14809 unseen_test_loss: 0.18817 \n",
      "Validation loss decreased (0.136414 --> 0.135307).  Saving model ...\n",
      "[17/50] train_loss: 0.13671 valid_loss: 0.13542 test_loss: 0.15050 unseen_test_loss: 0.19416 \n",
      "[18/50] train_loss: 0.13300 valid_loss: 0.13512 test_loss: 0.14574 unseen_test_loss: 0.19214 \n",
      "Validation loss decreased (0.135307 --> 0.135123).  Saving model ...\n",
      "[19/50] train_loss: 0.13608 valid_loss: 0.13239 test_loss: 0.14587 unseen_test_loss: 0.18423 \n",
      "Validation loss decreased (0.135123 --> 0.132393).  Saving model ...\n",
      "[20/50] train_loss: 0.12852 valid_loss: 0.12714 test_loss: 0.14156 unseen_test_loss: 0.18107 \n",
      "Validation loss decreased (0.132393 --> 0.127139).  Saving model ...\n",
      "[21/50] train_loss: 0.12767 valid_loss: 0.12500 test_loss: 0.13862 unseen_test_loss: 0.17234 \n",
      "Validation loss decreased (0.127139 --> 0.125003).  Saving model ...\n",
      "[22/50] train_loss: 0.12831 valid_loss: 0.12918 test_loss: 0.14173 unseen_test_loss: 0.18582 \n",
      "[23/50] train_loss: 0.12911 valid_loss: 0.12707 test_loss: 0.14050 unseen_test_loss: 0.18672 \n",
      "[24/50] train_loss: 0.12475 valid_loss: 0.12828 test_loss: 0.13880 unseen_test_loss: 0.18806 \n",
      "[25/50] train_loss: 0.12617 valid_loss: 0.12621 test_loss: 0.13666 unseen_test_loss: 0.17905 \n",
      "[26/50] train_loss: 0.12311 valid_loss: 0.12870 test_loss: 0.14096 unseen_test_loss: 0.19082 \n",
      "[27/50] train_loss: 0.12039 valid_loss: 0.12315 test_loss: 0.13500 unseen_test_loss: 0.18448 \n",
      "Validation loss decreased (0.125003 --> 0.123152).  Saving model ...\n",
      "[28/50] train_loss: 0.12166 valid_loss: 0.12118 test_loss: 0.13449 unseen_test_loss: 0.18312 \n",
      "Validation loss decreased (0.123152 --> 0.121180).  Saving model ...\n",
      "[29/50] train_loss: 0.12053 valid_loss: 0.11847 test_loss: 0.13301 unseen_test_loss: 0.18137 \n",
      "Validation loss decreased (0.121180 --> 0.118472).  Saving model ...\n",
      "[30/50] train_loss: 0.12053 valid_loss: 0.11967 test_loss: 0.13206 unseen_test_loss: 0.17842 \n",
      "[31/50] train_loss: 0.11692 valid_loss: 0.11899 test_loss: 0.13377 unseen_test_loss: 0.18334 \n",
      "[32/50] train_loss: 0.11775 valid_loss: 0.12012 test_loss: 0.13339 unseen_test_loss: 0.18437 \n",
      "[33/50] train_loss: 0.11637 valid_loss: 0.11790 test_loss: 0.13057 unseen_test_loss: 0.18104 \n",
      "Validation loss decreased (0.118472 --> 0.117902).  Saving model ...\n",
      "[34/50] train_loss: 0.11507 valid_loss: 0.11728 test_loss: 0.13148 unseen_test_loss: 0.17873 \n",
      "Validation loss decreased (0.117902 --> 0.117283).  Saving model ...\n",
      "[35/50] train_loss: 0.11437 valid_loss: 0.12066 test_loss: 0.13179 unseen_test_loss: 0.18740 \n",
      "[36/50] train_loss: 0.11405 valid_loss: 0.11587 test_loss: 0.13055 unseen_test_loss: 0.17547 \n",
      "Validation loss decreased (0.117283 --> 0.115866).  Saving model ...\n",
      "[37/50] train_loss: 0.11185 valid_loss: 0.11773 test_loss: 0.12783 unseen_test_loss: 0.17423 \n",
      "[38/50] train_loss: 0.11422 valid_loss: 0.11388 test_loss: 0.12805 unseen_test_loss: 0.17707 \n",
      "Validation loss decreased (0.115866 --> 0.113882).  Saving model ...\n",
      "[39/50] train_loss: 0.11405 valid_loss: 0.11655 test_loss: 0.12716 unseen_test_loss: 0.18368 \n",
      "[40/50] train_loss: 0.11023 valid_loss: 0.11415 test_loss: 0.12684 unseen_test_loss: 0.17912 \n",
      "[41/50] train_loss: 0.10889 valid_loss: 0.11531 test_loss: 0.12745 unseen_test_loss: 0.18042 \n",
      "[42/50] train_loss: 0.11104 valid_loss: 0.11709 test_loss: 0.12826 unseen_test_loss: 0.18863 \n",
      "[43/50] train_loss: 0.11185 valid_loss: 0.11299 test_loss: 0.12442 unseen_test_loss: 0.17098 \n",
      "Validation loss decreased (0.113882 --> 0.112993).  Saving model ...\n",
      "[44/50] train_loss: 0.11375 valid_loss: 0.11304 test_loss: 0.12644 unseen_test_loss: 0.17468 \n",
      "[45/50] train_loss: 0.11177 valid_loss: 0.11104 test_loss: 0.12387 unseen_test_loss: 0.17546 \n",
      "Validation loss decreased (0.112993 --> 0.111042).  Saving model ...\n",
      "[46/50] train_loss: 0.10919 valid_loss: 0.10967 test_loss: 0.12377 unseen_test_loss: 0.17819 \n",
      "Validation loss decreased (0.111042 --> 0.109670).  Saving model ...\n",
      "[47/50] train_loss: 0.10695 valid_loss: 0.10963 test_loss: 0.12301 unseen_test_loss: 0.17443 \n",
      "Validation loss decreased (0.109670 --> 0.109631).  Saving model ...\n",
      "[48/50] train_loss: 0.10688 valid_loss: 0.11361 test_loss: 0.12335 unseen_test_loss: 0.17740 \n",
      "[49/50] train_loss: 0.10590 valid_loss: 0.11005 test_loss: 0.12008 unseen_test_loss: 0.17905 \n",
      "[50/50] train_loss: 0.10385 valid_loss: 0.11007 test_loss: 0.12439 unseen_test_loss: 0.18132 \n",
      "saved results for model UKDALE_seen_1.pth\n",
      "TRAINING MODEL 2\n",
      "[ 1/50] train_loss: 0.60255 valid_loss: 0.50768 test_loss: 0.52196 unseen_test_loss: 0.48839 \n",
      "Validation loss decreased (inf --> 0.507681).  Saving model ...\n",
      "[ 2/50] train_loss: 0.42830 valid_loss: 0.36179 test_loss: 0.37255 unseen_test_loss: 0.35821 \n",
      "Validation loss decreased (0.507681 --> 0.361788).  Saving model ...\n",
      "[ 3/50] train_loss: 0.32095 valid_loss: 0.29085 test_loss: 0.30289 unseen_test_loss: 0.30023 \n",
      "Validation loss decreased (0.361788 --> 0.290852).  Saving model ...\n",
      "[ 4/50] train_loss: 0.26465 valid_loss: 0.24676 test_loss: 0.26146 unseen_test_loss: 0.27480 \n",
      "Validation loss decreased (0.290852 --> 0.246757).  Saving model ...\n",
      "[ 5/50] train_loss: 0.23006 valid_loss: 0.21784 test_loss: 0.23160 unseen_test_loss: 0.24972 \n",
      "Validation loss decreased (0.246757 --> 0.217836).  Saving model ...\n",
      "[ 6/50] train_loss: 0.20585 valid_loss: 0.20012 test_loss: 0.21330 unseen_test_loss: 0.23790 \n",
      "Validation loss decreased (0.217836 --> 0.200123).  Saving model ...\n",
      "[ 7/50] train_loss: 0.18517 valid_loss: 0.18572 test_loss: 0.19828 unseen_test_loss: 0.22645 \n",
      "Validation loss decreased (0.200123 --> 0.185718).  Saving model ...\n",
      "[ 8/50] train_loss: 0.17710 valid_loss: 0.17343 test_loss: 0.18635 unseen_test_loss: 0.21756 \n",
      "Validation loss decreased (0.185718 --> 0.173430).  Saving model ...\n",
      "[ 9/50] train_loss: 0.16615 valid_loss: 0.16388 test_loss: 0.17663 unseen_test_loss: 0.20761 \n",
      "Validation loss decreased (0.173430 --> 0.163883).  Saving model ...\n",
      "[10/50] train_loss: 0.16215 valid_loss: 0.15904 test_loss: 0.17277 unseen_test_loss: 0.20339 \n",
      "Validation loss decreased (0.163883 --> 0.159042).  Saving model ...\n",
      "[11/50] train_loss: 0.15926 valid_loss: 0.15220 test_loss: 0.16523 unseen_test_loss: 0.20277 \n",
      "Validation loss decreased (0.159042 --> 0.152199).  Saving model ...\n",
      "[12/50] train_loss: 0.15562 valid_loss: 0.14866 test_loss: 0.16041 unseen_test_loss: 0.19679 \n",
      "Validation loss decreased (0.152199 --> 0.148664).  Saving model ...\n",
      "[13/50] train_loss: 0.14797 valid_loss: 0.14343 test_loss: 0.15693 unseen_test_loss: 0.18836 \n",
      "Validation loss decreased (0.148664 --> 0.143426).  Saving model ...\n",
      "[14/50] train_loss: 0.14283 valid_loss: 0.14196 test_loss: 0.15345 unseen_test_loss: 0.18827 \n",
      "Validation loss decreased (0.143426 --> 0.141957).  Saving model ...\n",
      "[15/50] train_loss: 0.14460 valid_loss: 0.13856 test_loss: 0.15020 unseen_test_loss: 0.18411 \n",
      "Validation loss decreased (0.141957 --> 0.138562).  Saving model ...\n",
      "[16/50] train_loss: 0.13702 valid_loss: 0.13550 test_loss: 0.14733 unseen_test_loss: 0.18230 \n",
      "Validation loss decreased (0.138562 --> 0.135502).  Saving model ...\n",
      "[17/50] train_loss: 0.13528 valid_loss: 0.13236 test_loss: 0.14445 unseen_test_loss: 0.18213 \n",
      "Validation loss decreased (0.135502 --> 0.132362).  Saving model ...\n",
      "[18/50] train_loss: 0.13030 valid_loss: 0.13213 test_loss: 0.14290 unseen_test_loss: 0.17979 \n",
      "Validation loss decreased (0.132362 --> 0.132127).  Saving model ...\n",
      "[19/50] train_loss: 0.13110 valid_loss: 0.12743 test_loss: 0.14047 unseen_test_loss: 0.17380 \n",
      "Validation loss decreased (0.132127 --> 0.127425).  Saving model ...\n",
      "[20/50] train_loss: 0.12966 valid_loss: 0.12754 test_loss: 0.13996 unseen_test_loss: 0.17767 \n",
      "[21/50] train_loss: 0.12393 valid_loss: 0.12540 test_loss: 0.13809 unseen_test_loss: 0.17336 \n",
      "Validation loss decreased (0.127425 --> 0.125401).  Saving model ...\n",
      "[22/50] train_loss: 0.12330 valid_loss: 0.12162 test_loss: 0.13491 unseen_test_loss: 0.17420 \n",
      "Validation loss decreased (0.125401 --> 0.121622).  Saving model ...\n",
      "[23/50] train_loss: 0.12001 valid_loss: 0.12117 test_loss: 0.13456 unseen_test_loss: 0.17087 \n",
      "Validation loss decreased (0.121622 --> 0.121174).  Saving model ...\n",
      "[24/50] train_loss: 0.12127 valid_loss: 0.12122 test_loss: 0.13391 unseen_test_loss: 0.17252 \n",
      "[25/50] train_loss: 0.12100 valid_loss: 0.12250 test_loss: 0.13626 unseen_test_loss: 0.17258 \n",
      "[26/50] train_loss: 0.12023 valid_loss: 0.11881 test_loss: 0.13114 unseen_test_loss: 0.17057 \n",
      "Validation loss decreased (0.121174 --> 0.118807).  Saving model ...\n",
      "[27/50] train_loss: 0.11937 valid_loss: 0.11823 test_loss: 0.13016 unseen_test_loss: 0.16581 \n",
      "Validation loss decreased (0.118807 --> 0.118227).  Saving model ...\n",
      "[28/50] train_loss: 0.11792 valid_loss: 0.11500 test_loss: 0.12911 unseen_test_loss: 0.17038 \n",
      "Validation loss decreased (0.118227 --> 0.114996).  Saving model ...\n",
      "[29/50] train_loss: 0.11816 valid_loss: 0.11694 test_loss: 0.12991 unseen_test_loss: 0.16755 \n",
      "[30/50] train_loss: 0.11724 valid_loss: 0.11493 test_loss: 0.12852 unseen_test_loss: 0.16877 \n",
      "Validation loss decreased (0.114996 --> 0.114932).  Saving model ...\n",
      "[31/50] train_loss: 0.11038 valid_loss: 0.11605 test_loss: 0.12848 unseen_test_loss: 0.17412 \n",
      "[32/50] train_loss: 0.11210 valid_loss: 0.11248 test_loss: 0.12585 unseen_test_loss: 0.16825 \n",
      "Validation loss decreased (0.114932 --> 0.112482).  Saving model ...\n",
      "[33/50] train_loss: 0.11277 valid_loss: 0.11239 test_loss: 0.12733 unseen_test_loss: 0.17619 \n",
      "Validation loss decreased (0.112482 --> 0.112389).  Saving model ...\n",
      "[34/50] train_loss: 0.11167 valid_loss: 0.11071 test_loss: 0.12552 unseen_test_loss: 0.16556 \n",
      "Validation loss decreased (0.112389 --> 0.110710).  Saving model ...\n",
      "[35/50] train_loss: 0.11042 valid_loss: 0.11044 test_loss: 0.12319 unseen_test_loss: 0.16727 \n",
      "Validation loss decreased (0.110710 --> 0.110438).  Saving model ...\n",
      "[36/50] train_loss: 0.11092 valid_loss: 0.11001 test_loss: 0.12349 unseen_test_loss: 0.16452 \n",
      "Validation loss decreased (0.110438 --> 0.110013).  Saving model ...\n",
      "[37/50] train_loss: 0.10765 valid_loss: 0.11040 test_loss: 0.12164 unseen_test_loss: 0.16513 \n",
      "[38/50] train_loss: 0.10878 valid_loss: 0.11059 test_loss: 0.12261 unseen_test_loss: 0.17000 \n",
      "[39/50] train_loss: 0.10692 valid_loss: 0.11059 test_loss: 0.12250 unseen_test_loss: 0.16713 \n",
      "[40/50] train_loss: 0.10750 valid_loss: 0.10812 test_loss: 0.12171 unseen_test_loss: 0.16786 \n",
      "Validation loss decreased (0.110013 --> 0.108125).  Saving model ...\n",
      "[41/50] train_loss: 0.10727 valid_loss: 0.11154 test_loss: 0.12198 unseen_test_loss: 0.17632 \n",
      "[42/50] train_loss: 0.10346 valid_loss: 0.10736 test_loss: 0.11905 unseen_test_loss: 0.17445 \n",
      "Validation loss decreased (0.108125 --> 0.107359).  Saving model ...\n",
      "[43/50] train_loss: 0.10705 valid_loss: 0.10857 test_loss: 0.11880 unseen_test_loss: 0.17390 \n",
      "[44/50] train_loss: 0.10491 valid_loss: 0.10700 test_loss: 0.11966 unseen_test_loss: 0.17102 \n",
      "Validation loss decreased (0.107359 --> 0.106998).  Saving model ...\n",
      "[45/50] train_loss: 0.10247 valid_loss: 0.10554 test_loss: 0.11745 unseen_test_loss: 0.16298 \n",
      "Validation loss decreased (0.106998 --> 0.105539).  Saving model ...\n",
      "[46/50] train_loss: 0.10247 valid_loss: 0.11115 test_loss: 0.11967 unseen_test_loss: 0.18585 \n",
      "[47/50] train_loss: 0.10435 valid_loss: 0.10484 test_loss: 0.11686 unseen_test_loss: 0.17310 \n",
      "Validation loss decreased (0.105539 --> 0.104842).  Saving model ...\n",
      "[48/50] train_loss: 0.10262 valid_loss: 0.10613 test_loss: 0.11757 unseen_test_loss: 0.16720 \n",
      "[49/50] train_loss: 0.10182 valid_loss: 0.10620 test_loss: 0.11621 unseen_test_loss: 0.17053 \n",
      "[50/50] train_loss: 0.10438 valid_loss: 0.10320 test_loss: 0.11605 unseen_test_loss: 0.16552 \n",
      "Validation loss decreased (0.104842 --> 0.103201).  Saving model ...\n",
      "saved results for model UKDALE_seen_2.pth\n",
      "TRAINING MODEL 3\n",
      "[ 1/50] train_loss: 0.62232 valid_loss: 0.53261 test_loss: 0.55008 unseen_test_loss: 0.52126 \n",
      "Validation loss decreased (inf --> 0.532609).  Saving model ...\n",
      "[ 2/50] train_loss: 0.44675 valid_loss: 0.37535 test_loss: 0.40107 unseen_test_loss: 0.37299 \n",
      "Validation loss decreased (0.532609 --> 0.375349).  Saving model ...\n",
      "[ 3/50] train_loss: 0.33067 valid_loss: 0.29288 test_loss: 0.31830 unseen_test_loss: 0.30223 \n",
      "Validation loss decreased (0.375349 --> 0.292878).  Saving model ...\n",
      "[ 4/50] train_loss: 0.26647 valid_loss: 0.25175 test_loss: 0.27484 unseen_test_loss: 0.27218 \n",
      "Validation loss decreased (0.292878 --> 0.251752).  Saving model ...\n",
      "[ 5/50] train_loss: 0.22986 valid_loss: 0.21570 test_loss: 0.23701 unseen_test_loss: 0.24926 \n",
      "Validation loss decreased (0.251752 --> 0.215701).  Saving model ...\n",
      "[ 6/50] train_loss: 0.20295 valid_loss: 0.19546 test_loss: 0.21397 unseen_test_loss: 0.23201 \n",
      "Validation loss decreased (0.215701 --> 0.195461).  Saving model ...\n",
      "[ 7/50] train_loss: 0.18931 valid_loss: 0.18058 test_loss: 0.19760 unseen_test_loss: 0.22385 \n",
      "Validation loss decreased (0.195461 --> 0.180582).  Saving model ...\n",
      "[ 8/50] train_loss: 0.17878 valid_loss: 0.17114 test_loss: 0.18668 unseen_test_loss: 0.21471 \n",
      "Validation loss decreased (0.180582 --> 0.171142).  Saving model ...\n",
      "[ 9/50] train_loss: 0.17117 valid_loss: 0.16201 test_loss: 0.17540 unseen_test_loss: 0.20552 \n",
      "Validation loss decreased (0.171142 --> 0.162011).  Saving model ...\n",
      "[10/50] train_loss: 0.16211 valid_loss: 0.15744 test_loss: 0.17094 unseen_test_loss: 0.20091 \n",
      "Validation loss decreased (0.162011 --> 0.157441).  Saving model ...\n",
      "[11/50] train_loss: 0.15723 valid_loss: 0.14970 test_loss: 0.16458 unseen_test_loss: 0.19517 \n",
      "Validation loss decreased (0.157441 --> 0.149698).  Saving model ...\n",
      "[12/50] train_loss: 0.14597 valid_loss: 0.14569 test_loss: 0.16010 unseen_test_loss: 0.18908 \n",
      "Validation loss decreased (0.149698 --> 0.145688).  Saving model ...\n",
      "[13/50] train_loss: 0.14127 valid_loss: 0.14164 test_loss: 0.15761 unseen_test_loss: 0.18798 \n",
      "Validation loss decreased (0.145688 --> 0.141635).  Saving model ...\n",
      "[14/50] train_loss: 0.14463 valid_loss: 0.13880 test_loss: 0.15303 unseen_test_loss: 0.18552 \n",
      "Validation loss decreased (0.141635 --> 0.138804).  Saving model ...\n",
      "[15/50] train_loss: 0.14083 valid_loss: 0.13501 test_loss: 0.14807 unseen_test_loss: 0.18175 \n",
      "Validation loss decreased (0.138804 --> 0.135009).  Saving model ...\n",
      "[16/50] train_loss: 0.13735 valid_loss: 0.13571 test_loss: 0.14683 unseen_test_loss: 0.18183 \n",
      "[17/50] train_loss: 0.13457 valid_loss: 0.13225 test_loss: 0.14511 unseen_test_loss: 0.17985 \n",
      "Validation loss decreased (0.135009 --> 0.132252).  Saving model ...\n",
      "[18/50] train_loss: 0.13318 valid_loss: 0.13039 test_loss: 0.14527 unseen_test_loss: 0.17840 \n",
      "Validation loss decreased (0.132252 --> 0.130387).  Saving model ...\n",
      "[19/50] train_loss: 0.12970 valid_loss: 0.13083 test_loss: 0.14201 unseen_test_loss: 0.17445 \n",
      "[20/50] train_loss: 0.12593 valid_loss: 0.12764 test_loss: 0.14055 unseen_test_loss: 0.18002 \n",
      "Validation loss decreased (0.130387 --> 0.127642).  Saving model ...\n",
      "[21/50] train_loss: 0.12872 valid_loss: 0.12500 test_loss: 0.13880 unseen_test_loss: 0.17250 \n",
      "Validation loss decreased (0.127642 --> 0.125003).  Saving model ...\n",
      "[22/50] train_loss: 0.12612 valid_loss: 0.12538 test_loss: 0.13676 unseen_test_loss: 0.17470 \n",
      "[23/50] train_loss: 0.12279 valid_loss: 0.12194 test_loss: 0.13472 unseen_test_loss: 0.17108 \n",
      "Validation loss decreased (0.125003 --> 0.121944).  Saving model ...\n",
      "[24/50] train_loss: 0.12123 valid_loss: 0.12317 test_loss: 0.13438 unseen_test_loss: 0.17267 \n",
      "[25/50] train_loss: 0.12479 valid_loss: 0.12242 test_loss: 0.13320 unseen_test_loss: 0.17475 \n",
      "[26/50] train_loss: 0.11762 valid_loss: 0.11824 test_loss: 0.13163 unseen_test_loss: 0.16908 \n",
      "Validation loss decreased (0.121944 --> 0.118237).  Saving model ...\n",
      "[27/50] train_loss: 0.12062 valid_loss: 0.11726 test_loss: 0.12929 unseen_test_loss: 0.16722 \n",
      "Validation loss decreased (0.118237 --> 0.117256).  Saving model ...\n",
      "[28/50] train_loss: 0.11868 valid_loss: 0.11857 test_loss: 0.13082 unseen_test_loss: 0.16868 \n",
      "[29/50] train_loss: 0.11330 valid_loss: 0.11835 test_loss: 0.12962 unseen_test_loss: 0.17341 \n",
      "[30/50] train_loss: 0.11934 valid_loss: 0.12054 test_loss: 0.12952 unseen_test_loss: 0.17641 \n",
      "[31/50] train_loss: 0.11303 valid_loss: 0.12204 test_loss: 0.13095 unseen_test_loss: 0.17581 \n",
      "[32/50] train_loss: 0.11525 valid_loss: 0.11618 test_loss: 0.12547 unseen_test_loss: 0.16790 \n",
      "Validation loss decreased (0.117256 --> 0.116178).  Saving model ...\n",
      "[33/50] train_loss: 0.11270 valid_loss: 0.11248 test_loss: 0.12575 unseen_test_loss: 0.16847 \n",
      "Validation loss decreased (0.116178 --> 0.112483).  Saving model ...\n",
      "[34/50] train_loss: 0.11160 valid_loss: 0.11521 test_loss: 0.12560 unseen_test_loss: 0.16776 \n",
      "[35/50] train_loss: 0.11077 valid_loss: 0.11300 test_loss: 0.12396 unseen_test_loss: 0.17168 \n",
      "[36/50] train_loss: 0.11188 valid_loss: 0.11182 test_loss: 0.12394 unseen_test_loss: 0.16994 \n",
      "Validation loss decreased (0.112483 --> 0.111817).  Saving model ...\n",
      "[37/50] train_loss: 0.10862 valid_loss: 0.11042 test_loss: 0.12351 unseen_test_loss: 0.16911 \n",
      "Validation loss decreased (0.111817 --> 0.110421).  Saving model ...\n",
      "[38/50] train_loss: 0.11222 valid_loss: 0.11153 test_loss: 0.12232 unseen_test_loss: 0.16858 \n",
      "[39/50] train_loss: 0.10866 valid_loss: 0.11024 test_loss: 0.12182 unseen_test_loss: 0.16758 \n",
      "Validation loss decreased (0.110421 --> 0.110242).  Saving model ...\n",
      "[40/50] train_loss: 0.10723 valid_loss: 0.10983 test_loss: 0.11990 unseen_test_loss: 0.16717 \n",
      "Validation loss decreased (0.110242 --> 0.109827).  Saving model ...\n",
      "[41/50] train_loss: 0.10804 valid_loss: 0.10914 test_loss: 0.12030 unseen_test_loss: 0.16535 \n",
      "Validation loss decreased (0.109827 --> 0.109137).  Saving model ...\n",
      "[42/50] train_loss: 0.10902 valid_loss: 0.10917 test_loss: 0.11968 unseen_test_loss: 0.17262 \n",
      "[43/50] train_loss: 0.10668 valid_loss: 0.11206 test_loss: 0.11906 unseen_test_loss: 0.16859 \n",
      "[44/50] train_loss: 0.10846 valid_loss: 0.10706 test_loss: 0.11802 unseen_test_loss: 0.16056 \n",
      "Validation loss decreased (0.109137 --> 0.107060).  Saving model ...\n",
      "[45/50] train_loss: 0.10663 valid_loss: 0.11050 test_loss: 0.11795 unseen_test_loss: 0.16690 \n",
      "[46/50] train_loss: 0.10306 valid_loss: 0.10588 test_loss: 0.11804 unseen_test_loss: 0.16999 \n",
      "Validation loss decreased (0.107060 --> 0.105877).  Saving model ...\n",
      "[47/50] train_loss: 0.10387 valid_loss: 0.10710 test_loss: 0.11991 unseen_test_loss: 0.17394 \n",
      "[48/50] train_loss: 0.10261 valid_loss: 0.10536 test_loss: 0.11659 unseen_test_loss: 0.16381 \n",
      "Validation loss decreased (0.105877 --> 0.105357).  Saving model ...\n",
      "[49/50] train_loss: 0.10359 valid_loss: 0.10671 test_loss: 0.11684 unseen_test_loss: 0.17271 \n",
      "[50/50] train_loss: 0.10158 valid_loss: 0.10654 test_loss: 0.11592 unseen_test_loss: 0.16902 \n",
      "saved results for model UKDALE_seen_3.pth\n",
      "TRAINING MODEL 4\n",
      "[ 1/50] train_loss: 0.59787 valid_loss: 0.51560 test_loss: 0.53143 unseen_test_loss: 0.49491 \n",
      "Validation loss decreased (inf --> 0.515601).  Saving model ...\n",
      "[ 2/50] train_loss: 0.41845 valid_loss: 0.34968 test_loss: 0.36942 unseen_test_loss: 0.34456 \n",
      "Validation loss decreased (0.515601 --> 0.349682).  Saving model ...\n",
      "[ 3/50] train_loss: 0.30930 valid_loss: 0.28617 test_loss: 0.30198 unseen_test_loss: 0.28968 \n",
      "Validation loss decreased (0.349682 --> 0.286174).  Saving model ...\n",
      "[ 4/50] train_loss: 0.25828 valid_loss: 0.24490 test_loss: 0.26025 unseen_test_loss: 0.26364 \n",
      "Validation loss decreased (0.286174 --> 0.244899).  Saving model ...\n",
      "[ 5/50] train_loss: 0.23059 valid_loss: 0.21957 test_loss: 0.23321 unseen_test_loss: 0.25192 \n",
      "Validation loss decreased (0.244899 --> 0.219574).  Saving model ...\n",
      "[ 6/50] train_loss: 0.20530 valid_loss: 0.20142 test_loss: 0.21555 unseen_test_loss: 0.24115 \n",
      "Validation loss decreased (0.219574 --> 0.201424).  Saving model ...\n",
      "[ 7/50] train_loss: 0.18826 valid_loss: 0.18417 test_loss: 0.19640 unseen_test_loss: 0.22392 \n",
      "Validation loss decreased (0.201424 --> 0.184167).  Saving model ...\n",
      "[ 8/50] train_loss: 0.17738 valid_loss: 0.17048 test_loss: 0.18428 unseen_test_loss: 0.20907 \n",
      "Validation loss decreased (0.184167 --> 0.170478).  Saving model ...\n",
      "[ 9/50] train_loss: 0.16952 valid_loss: 0.16317 test_loss: 0.17612 unseen_test_loss: 0.20847 \n",
      "Validation loss decreased (0.170478 --> 0.163175).  Saving model ...\n",
      "[10/50] train_loss: 0.16271 valid_loss: 0.15823 test_loss: 0.16969 unseen_test_loss: 0.20453 \n",
      "Validation loss decreased (0.163175 --> 0.158232).  Saving model ...\n",
      "[11/50] train_loss: 0.15664 valid_loss: 0.15170 test_loss: 0.16288 unseen_test_loss: 0.19691 \n",
      "Validation loss decreased (0.158232 --> 0.151702).  Saving model ...\n",
      "[12/50] train_loss: 0.14865 valid_loss: 0.14630 test_loss: 0.15865 unseen_test_loss: 0.19243 \n",
      "Validation loss decreased (0.151702 --> 0.146297).  Saving model ...\n",
      "[13/50] train_loss: 0.14714 valid_loss: 0.14309 test_loss: 0.15458 unseen_test_loss: 0.19316 \n",
      "Validation loss decreased (0.146297 --> 0.143094).  Saving model ...\n",
      "[14/50] train_loss: 0.14506 valid_loss: 0.13921 test_loss: 0.15199 unseen_test_loss: 0.18755 \n",
      "Validation loss decreased (0.143094 --> 0.139206).  Saving model ...\n",
      "[15/50] train_loss: 0.14110 valid_loss: 0.13527 test_loss: 0.14881 unseen_test_loss: 0.18483 \n",
      "Validation loss decreased (0.139206 --> 0.135273).  Saving model ...\n",
      "[16/50] train_loss: 0.13660 valid_loss: 0.13629 test_loss: 0.14854 unseen_test_loss: 0.19606 \n",
      "[17/50] train_loss: 0.13338 valid_loss: 0.13287 test_loss: 0.14478 unseen_test_loss: 0.18523 \n",
      "Validation loss decreased (0.135273 --> 0.132874).  Saving model ...\n",
      "[18/50] train_loss: 0.13382 valid_loss: 0.13330 test_loss: 0.14236 unseen_test_loss: 0.18983 \n",
      "[19/50] train_loss: 0.13216 valid_loss: 0.12913 test_loss: 0.14184 unseen_test_loss: 0.18623 \n",
      "Validation loss decreased (0.132874 --> 0.129132).  Saving model ...\n",
      "[20/50] train_loss: 0.12886 valid_loss: 0.12878 test_loss: 0.14032 unseen_test_loss: 0.18200 \n",
      "Validation loss decreased (0.129132 --> 0.128782).  Saving model ...\n",
      "[21/50] train_loss: 0.12524 valid_loss: 0.12631 test_loss: 0.13780 unseen_test_loss: 0.18004 \n",
      "Validation loss decreased (0.128782 --> 0.126311).  Saving model ...\n",
      "[22/50] train_loss: 0.12462 valid_loss: 0.12841 test_loss: 0.14034 unseen_test_loss: 0.19190 \n",
      "[23/50] train_loss: 0.12452 valid_loss: 0.12397 test_loss: 0.13394 unseen_test_loss: 0.17620 \n",
      "Validation loss decreased (0.126311 --> 0.123973).  Saving model ...\n",
      "[24/50] train_loss: 0.12422 valid_loss: 0.12184 test_loss: 0.13413 unseen_test_loss: 0.17928 \n",
      "Validation loss decreased (0.123973 --> 0.121841).  Saving model ...\n",
      "[25/50] train_loss: 0.12353 valid_loss: 0.12602 test_loss: 0.13752 unseen_test_loss: 0.19378 \n",
      "[26/50] train_loss: 0.12311 valid_loss: 0.12267 test_loss: 0.13236 unseen_test_loss: 0.17944 \n",
      "[27/50] train_loss: 0.11753 valid_loss: 0.12164 test_loss: 0.13098 unseen_test_loss: 0.17737 \n",
      "Validation loss decreased (0.121841 --> 0.121644).  Saving model ...\n",
      "[28/50] train_loss: 0.11758 valid_loss: 0.12059 test_loss: 0.13233 unseen_test_loss: 0.18325 \n",
      "Validation loss decreased (0.121644 --> 0.120595).  Saving model ...\n",
      "[29/50] train_loss: 0.11829 valid_loss: 0.11772 test_loss: 0.13024 unseen_test_loss: 0.17690 \n",
      "Validation loss decreased (0.120595 --> 0.117716).  Saving model ...\n",
      "[30/50] train_loss: 0.11928 valid_loss: 0.11988 test_loss: 0.13334 unseen_test_loss: 0.18315 \n",
      "[31/50] train_loss: 0.11969 valid_loss: 0.11781 test_loss: 0.12795 unseen_test_loss: 0.17526 \n",
      "[32/50] train_loss: 0.11761 valid_loss: 0.11324 test_loss: 0.12775 unseen_test_loss: 0.17876 \n",
      "Validation loss decreased (0.117716 --> 0.113239).  Saving model ...\n",
      "[33/50] train_loss: 0.11372 valid_loss: 0.11305 test_loss: 0.12499 unseen_test_loss: 0.17415 \n",
      "Validation loss decreased (0.113239 --> 0.113053).  Saving model ...\n",
      "[34/50] train_loss: 0.11425 valid_loss: 0.11116 test_loss: 0.12552 unseen_test_loss: 0.17205 \n",
      "Validation loss decreased (0.113053 --> 0.111160).  Saving model ...\n",
      "[35/50] train_loss: 0.11575 valid_loss: 0.11266 test_loss: 0.12467 unseen_test_loss: 0.17991 \n",
      "[36/50] train_loss: 0.11033 valid_loss: 0.11187 test_loss: 0.12405 unseen_test_loss: 0.17451 \n",
      "[37/50] train_loss: 0.11423 valid_loss: 0.11051 test_loss: 0.12339 unseen_test_loss: 0.16795 \n",
      "Validation loss decreased (0.111160 --> 0.110511).  Saving model ...\n",
      "[38/50] train_loss: 0.10795 valid_loss: 0.11020 test_loss: 0.12295 unseen_test_loss: 0.17208 \n",
      "Validation loss decreased (0.110511 --> 0.110200).  Saving model ...\n",
      "[39/50] train_loss: 0.11254 valid_loss: 0.10803 test_loss: 0.12154 unseen_test_loss: 0.17667 \n",
      "Validation loss decreased (0.110200 --> 0.108031).  Saving model ...\n",
      "[40/50] train_loss: 0.11017 valid_loss: 0.11009 test_loss: 0.12385 unseen_test_loss: 0.17856 \n",
      "[41/50] train_loss: 0.10852 valid_loss: 0.10879 test_loss: 0.12269 unseen_test_loss: 0.17607 \n",
      "[42/50] train_loss: 0.10883 valid_loss: 0.10807 test_loss: 0.12021 unseen_test_loss: 0.17347 \n",
      "[43/50] train_loss: 0.10897 valid_loss: 0.10739 test_loss: 0.12199 unseen_test_loss: 0.16965 \n",
      "Validation loss decreased (0.108031 --> 0.107389).  Saving model ...\n",
      "[44/50] train_loss: 0.11000 valid_loss: 0.10816 test_loss: 0.12009 unseen_test_loss: 0.17838 \n",
      "[45/50] train_loss: 0.10523 valid_loss: 0.10709 test_loss: 0.11910 unseen_test_loss: 0.16847 \n",
      "Validation loss decreased (0.107389 --> 0.107089).  Saving model ...\n",
      "[46/50] train_loss: 0.10565 valid_loss: 0.10888 test_loss: 0.11952 unseen_test_loss: 0.17562 \n",
      "[47/50] train_loss: 0.10437 valid_loss: 0.10535 test_loss: 0.11875 unseen_test_loss: 0.17500 \n",
      "Validation loss decreased (0.107089 --> 0.105352).  Saving model ...\n",
      "[48/50] train_loss: 0.10456 valid_loss: 0.10571 test_loss: 0.11860 unseen_test_loss: 0.17901 \n",
      "[49/50] train_loss: 0.10246 valid_loss: 0.10526 test_loss: 0.11808 unseen_test_loss: 0.17355 \n",
      "Validation loss decreased (0.105352 --> 0.105262).  Saving model ...\n",
      "[50/50] train_loss: 0.10318 valid_loss: 0.10916 test_loss: 0.11889 unseen_test_loss: 0.17882 \n",
      "saved results for model UKDALE_seen_4.pth\n"
     ]
    }
   ],
   "source": [
    "# training code adaptation: short and simple, just to see that it lives \n",
    "# (later on we will run the original code to recreate the results):\n",
    "\n",
    "batch_size = BATCH_SIZE\n",
    "n_epochs = 50 # a modification here\n",
    "\n",
    "train_loader = dl_train_seen\n",
    "valid_loader = dl_valid_seen\n",
    "test_loader = dl_test_seen\n",
    "#unseen test loader\n",
    "unseen_test_loader = dl_test_unseen\n",
    "\n",
    "\n",
    "res_dict = {}\n",
    "\n",
    "#i = 0\n",
    "for i in range(5): # another modification here\n",
    "    print('TRAINING MODEL %d' %i)\n",
    "    # Instantiate the model\n",
    "    model = PTPNet(1,3,32).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1.E-4)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    fn = 'UKDALE_seen_%d.pth' %i\n",
    "    model, train_loss, valid_loss, test_loss, unseen_test_loss = train_model(model, batch_size, n_epochs, fn)\n",
    "    \n",
    "    res_dict['UKDALE_model_' + str(i)+'_results'] = {'model_name': fn, \n",
    "                                                    'train_loss': train_loss, \n",
    "                                                    'valid_loss': valid_loss, \n",
    "                                                    'test_loss': test_loss,\n",
    "                                                    'unseen_test_loss': unseen_test_loss}\n",
    "\n",
    "    # save res_dict to a file\n",
    "    with open('res_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(res_dict, f)\n",
    "        print('saved results for model ' + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sh-_NRsnPkdC",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss values\n",
    "plt.plot(train_loss, label='Seen Training Loss')\n",
    "plt.plot(valid_loss, label='Seen Validation Loss')\n",
    "plt.plot(test_loss, label='Seen Test Loss')\n",
    "\n",
    "plt.plot(unseen_test_loss, label='Unseen Test Loss')\n",
    "\n",
    "\n",
    "# Set the y-axis to a logarithmic scale\n",
    "plt.yscale('log')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Epochs')  # Replace with 'Iterations' if appropriate\n",
    "plt.ylabel('Loss (log scale)')\n",
    "plt.title('Loss Curves for Seen Training, Validation, and Testing, and Unseen testing')\n",
    "\n",
    "# Add a legend to distinguish the lines\n",
    "plt.legend()\n",
    "\n",
    "# Display grid for better readability\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulated datasets and dataloaders (the manipulation is on the train and validation):\n",
    "\n",
    "ds_house_train = [Power(ds_meter[i][:int(0.8*ds_len[i])], \n",
    "                        ds_appliance[i][:int(0.8*ds_len[i])], \n",
    "                        ds_status[i][:int(0.8*ds_len[i])], \n",
    "                        SEQ_LEN, BORDER, MAX_POWER, True) for i in range(5+0)]\n",
    "\n",
    "ds_house_valid = [Power(ds_meter[i][int(0.8*ds_len[i]):int(0.9*ds_len[i])], \n",
    "                        ds_appliance[i][int(0.8*ds_len[i]):int(0.9*ds_len[i])],\n",
    "                        ds_status[i][int(0.8*ds_len[i]):int(0.9*ds_len[i])], \n",
    "                        SEQ_LEN, BORDER, MAX_POWER, False) for i in range(5+0)]\n",
    "\n",
    "ds_train_seen = torch.utils.data.ConcatDataset([ds_house_train[0], \n",
    "                                                ds_house_train[1]\n",
    "                                                ])\n",
    "ds_valid_seen = torch.utils.data.ConcatDataset([ds_house_valid[0], \n",
    "                                                ds_house_valid[1]\n",
    "                                                ])\n",
    "\n",
    "dl_train_seen = DataLoader(dataset = ds_train_seen, batch_size = BATCH_SIZE, shuffle=True)\n",
    "dl_valid_seen = DataLoader(dataset = ds_valid_seen, batch_size = BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MANIPULATED MODEL 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[0;32m     22\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUKDALE_seen_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_manipulated_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39mi\n\u001b[1;32m---> 23\u001b[0m mm_model, mm_train_loss, mm_valid_loss, mm_test_loss, mm_unseen_test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m manipulated_model_res_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUKDALE_manipulated_model_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_results\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m: fn, \n\u001b[0;32m     26\u001b[0m                                                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: mm_modeltrain_loss, \n\u001b[0;32m     27\u001b[0m                                                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: mm_modelvalid_loss, \n\u001b[0;32m     28\u001b[0m                                                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: mm_modeltest_loss,\n\u001b[0;32m     29\u001b[0m                                                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munseen_test_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: mm_unseen_test_loss}\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# save res_dict to a file\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[51], line 40\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, batch_size, n_epochs, filename)\u001b[0m\n\u001b[0;32m     38\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# forward pass: compute predicted outputs by passing inputs to the model\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m output_status \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# calculate the loss\u001b[39;00m\n\u001b[0;32m     42\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output_status, target_status)\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[19], line 73\u001b[0m, in \u001b[0;36mPTPNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     71\u001b[0m tp2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtpool2(enc4)\n\u001b[0;32m     72\u001b[0m tp3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtpool3(enc4)\n\u001b[1;32m---> 73\u001b[0m tp4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtpool4\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc4\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m dec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(torch\u001b[38;5;241m.\u001b[39mcat([enc4, tp1, tp2, tp3, tp4], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     77\u001b[0m act \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(dec)\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[19], line 28\u001b[0m, in \u001b[0;36mTemporalPooling.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(F\u001b[38;5;241m.\u001b[39mrelu(x))\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#return self.upsample(x)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#return self.drop(self.upsample(x))\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\nn\\modules\\dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\nn\\functional.py:1295\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# manipulated data model training\n",
    "\n",
    "batch_size = BATCH_SIZE\n",
    "n_epochs = 50 # a modification here\n",
    "\n",
    "train_loader = dl_train_seen\n",
    "valid_loader = dl_valid_seen\n",
    "test_loader = dl_test_seen\n",
    "#unseen test loader\n",
    "unseen_test_loader = dl_test_unseen\n",
    "\n",
    "\n",
    "mm_res_dict = {}\n",
    "\n",
    "#i = 0\n",
    "for i in range(1): # another modification here\n",
    "    print('TRAINING MANIPULATED MODEL %d' %i)\n",
    "    # Instantiate the model\n",
    "    model = PTPNet(1,3,32).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1.E-4)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    fn = 'UKDALE_seen_%d_manipulated_model.pth' %i\n",
    "    mm_model, mm_train_loss, mm_valid_loss, mm_test_loss, mm_unseen_test_loss = train_model(model, batch_size, n_epochs, fn)\n",
    "    \n",
    "    manipulated_model_res_dict['UKDALE_manipulated_model_' + str(i)+'_results'] = {'model_name': fn, \n",
    "                                                    'train_loss': mm_modeltrain_loss, \n",
    "                                                    'valid_loss': mm_modelvalid_loss, \n",
    "                                                    'test_loss': mm_modeltest_loss,\n",
    "                                                    'unseen_test_loss': mm_unseen_test_loss}\n",
    "\n",
    "    # save res_dict to a file\n",
    "    with open('manipulated_model_res_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(mm_res_dict, f)\n",
    "        print('saved results for model ' + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sh-_NRsnPkdC"
   },
   "outputs": [],
   "source": [
    "# Manipulated Model plots\n",
    "\n",
    "# Plot the loss values\n",
    "plt.plot(best_model_train_loss, label='Seen Training Loss')\n",
    "plt.plot(best_model_valid_loss, label='Seen Validation Loss')\n",
    "plt.plot(best_model_test_loss, label='Seen Test Loss')\n",
    "\n",
    "plt.plot(best_model_unseen_test_loss, label='Unseen Test Loss')\n",
    "\n",
    "\n",
    "# Set the y-axis to a logarithmic scale\n",
    "plt.yscale('log')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Epochs')  # Replace with 'Iterations' if appropriate\n",
    "plt.ylabel('Loss (log scale)')\n",
    "plt.title('Best Model Loss Curves for Seen Training, Validation, and Testing, and Unseen testing')\n",
    "\n",
    "# Add a legend to distinguish the lines\n",
    "plt.legend()\n",
    "\n",
    "# Display grid for better readability\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzBMEXOuEDrj"
   },
   "outputs": [],
   "source": [
    "# the unseen part seems wrong, and isn't at use at the moment.\n",
    "\n",
    "# batch_size = BATCH_SIZE\n",
    "# n_epochs = 100\n",
    "\n",
    "# train_loader = dl_train_unseen\n",
    "# valid_loader = dl_valid_unseen\n",
    "# test_loader = dl_test_unseen\n",
    "\n",
    "# #i = 0\n",
    "# for i in range(20):\n",
    "#     print('TRAINING MODEL %d' %i)\n",
    "#     # Instantiate the model\n",
    "#     model = PTPNet(1,3,32).to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=1.E-4)\n",
    "#     criterion = nn.BCEWithLogitsLoss()\n",
    "#     fn = 'UKDALE_unseen_%d.pth' %i\n",
    "#     model, train_loss, valid_loss, test_loss = train_model(model, batch_size, n_epochs, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qYrzbsFJEThv"
   },
   "outputs": [],
   "source": [
    "# plt.plot(train_loss)\n",
    "# plt.plot(valid_loss)\n",
    "# plt.plot(test_loss)\n",
    "\n",
    "# plt.yscale('log')\n",
    "# plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "colab_type": "code",
    "id": "MD1z2vUwyZIH",
    "outputId": "42c5af30-c246-4805-8ce7-2a7fbe79176c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PTPNet(\n",
       "  (encoder1): Encoder(\n",
       "    (conv): Conv1d(1, 32, kernel_size=(3,), stride=(1,), bias=False)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (encoder2): Encoder(\n",
       "    (conv): Conv1d(32, 64, kernel_size=(3,), stride=(1,), bias=False)\n",
       "    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (encoder3): Encoder(\n",
       "    (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), bias=False)\n",
       "    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (pool3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (encoder4): Encoder(\n",
       "    (conv): Conv1d(128, 256, kernel_size=(3,), stride=(1,), bias=False)\n",
       "    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (tpool1): TemporalPooling(\n",
       "    (pool): AvgPool1d(kernel_size=(5,), stride=(5,), padding=(0,))\n",
       "    (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (tpool2): TemporalPooling(\n",
       "    (pool): AvgPool1d(kernel_size=(10,), stride=(10,), padding=(0,))\n",
       "    (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (tpool3): TemporalPooling(\n",
       "    (pool): AvgPool1d(kernel_size=(20,), stride=(20,), padding=(0,))\n",
       "    (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (tpool4): TemporalPooling(\n",
       "    (pool): AvgPool1d(kernel_size=(30,), stride=(30,), padding=(0,))\n",
       "    (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (conv): ConvTranspose1d(512, 32, kernel_size=(8,), stride=(8,), bias=False)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (activation): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PTPNet(1,3,32).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./UKDALE_seen_0.pth\n",
      "./UKDALE_seen_1.pth\n",
      "./UKDALE_seen_2.pth\n",
      "./UKDALE_seen_3.pth\n",
      "./UKDALE_seen_4.pth\n",
      "\n",
      "fridge\n",
      "F1 score  : 0.815 (0.812, 0.818)\n",
      "Precision : 0.826 (0.819, 0.839)\n",
      "Recall    : 0.805 (0.787, 0.821)\n",
      "Accuracy  : 0.835 (0.833, 0.835)\n",
      "MCC       : 0.666 (0.664, 0.666)\n",
      "MAE       : 19.20 (19.08, 19.31)\n",
      "SAE       : -0.027 (-0.063, 0.001)\n",
      "\n",
      "dish_washer\n",
      "F1 score  : 0.864 (0.852, 0.861)\n",
      "Precision : 0.927 (0.923, 0.940)\n",
      "Recall    : 0.810 (0.789, 0.818)\n",
      "Accuracy  : 0.994 (0.993, 0.994)\n",
      "MCC       : 0.863 (0.850, 0.862)\n",
      "MAE       : 20.14 (19.70, 20.66)\n",
      "SAE       : -0.142 (-0.182, -0.098)\n",
      "\n",
      "washing_machine\n",
      "F1 score  : 0.966 (0.963, 0.969)\n",
      "Precision : 0.957 (0.953, 0.959)\n",
      "Recall    : 0.975 (0.971, 0.976)\n",
      "Accuracy  : 0.995 (0.995, 0.995)\n",
      "MCC       : 0.963 (0.960, 0.967)\n",
      "MAE       : 42.58 (42.50, 42.82)\n",
      "SAE       : -0.066 (-0.068, -0.061)\n"
     ]
    }
   ],
   "source": [
    "# this is a modified code- to make it run faster\n",
    "\n",
    "scores = {}\n",
    "for a in range(3):\n",
    "    scores[a] = {}\n",
    "    scores[a]['F1'] = []\n",
    "    scores[a]['Precision'] = []\n",
    "    scores[a]['Recall'] = []\n",
    "    scores[a]['Accuracy'] = []\n",
    "    scores[a]['MCC'] = []\n",
    "    scores[a]['MAE'] = []\n",
    "    scores[a]['SAE'] = []\n",
    "\n",
    "thr = 0.5\n",
    "for i in range(5):\n",
    "    #filename = '/content/gdrive/My Drive/NILM/UKDALE_seen_%d.pth' %i\n",
    "    filename = './UKDALE_seen_%d.pth' %i\n",
    "    print(filename)\n",
    "    model.load_state_dict(torch.load(filename, weights_only=True))\n",
    "    for a in range(3):\n",
    "        #x_true, p_true, s_true, s_hat = evaluate_activation(model, dl_house_total[0], a)\n",
    "        #pm = p_true.sum() / s_true.sum()\n",
    "        #pm = (ds_appliance[0][APPLIANCE[a]] * \n",
    "        #      ds_status[0][APPLIANCE[a]]).sum() / ds_status[0][APPLIANCE[a]].sum() / MAX_POWER\n",
    "        pm = ds_appliance[0][APPLIANCE[a]].sum() / ds_status[0][APPLIANCE[a]].sum() / MAX_POWER\n",
    "        x_true, p_true, s_true, s_hat = evaluate_activation(model, dl_house_test[0], a)\n",
    "        s_hat = get_status(s_hat, thr, MIN_OFF[a], MIN_ON[a])\n",
    "        p_hat = pm * s_hat\n",
    "        scores[a]['F1'].append(f1_score(s_true, s_hat))\n",
    "        scores[a]['Precision'].append(precision_score(s_true, s_hat))\n",
    "        scores[a]['Recall'].append(recall_score(s_true, s_hat))\n",
    "        scores[a]['Accuracy'].append(accuracy_score(s_true, s_hat))\n",
    "        scores[a]['MCC'].append(matthews_corrcoef(s_true, s_hat))\n",
    "        scores[a]['MAE'].append(mean_absolute_error(p_true, p_hat)*MAX_POWER)\n",
    "        scores[a]['SAE'].append((p_hat.sum() - p_true.sum()) / p_true.sum())\n",
    "\n",
    "for i,a in enumerate(APPLIANCE):\n",
    "    print()\n",
    "    print(a)\n",
    "    print('F1 score  : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['F1']), sorted(scores[i]['F1'])[1], sorted(scores[i]['F1'])[3]))\n",
    "    print('Precision : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['Precision']), sorted(scores[i]['Precision'])[1], sorted(scores[i]['Precision'])[3]))\n",
    "    print('Recall    : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['Recall']), sorted(scores[i]['Recall'])[1], sorted(scores[i]['Recall'])[3]))\n",
    "    print('Accuracy  : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['Accuracy']), sorted(scores[i]['Accuracy'])[1], sorted(scores[i]['Accuracy'])[3]))\n",
    "    print('MCC       : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['MCC']), sorted(scores[i]['MCC'])[1], sorted(scores[i]['MCC'])[3]))\n",
    "    print('MAE       : %.2f (%.2f, %.2f)' %(np.mean(scores[i]['MAE']), sorted(scores[i]['MAE'])[1], sorted(scores[i]['MAE'])[3]))\n",
    "    print('SAE       : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['SAE']), sorted(scores[i]['SAE'])[1], sorted(scores[i]['SAE'])[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "HuXotkW1yd-b",
    "outputId": "49ef336e-dab6-470f-ab7c-7ed83a4c4162",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is the original code\n",
    "\n",
    "# scores = {}\n",
    "# for a in range(3):\n",
    "#     scores[a] = {}\n",
    "#     scores[a]['F1'] = []\n",
    "#     scores[a]['Precision'] = []\n",
    "#     scores[a]['Recall'] = []\n",
    "#     scores[a]['Accuracy'] = []\n",
    "#     scores[a]['MCC'] = []\n",
    "#     scores[a]['MAE'] = []\n",
    "#     scores[a]['SAE'] = []\n",
    "\n",
    "# thr = 0.5\n",
    "# for i in range(20):\n",
    "#     #filename = '/content/gdrive/My Drive/NILM/UKDALE_seen_%d.pth' %i\n",
    "#     filename = './UKDALE_seen_%d.pth' %i\n",
    "#     print(filename)\n",
    "#     model.load_state_dict(torch.load(filename))\n",
    "#     for a in range(3):\n",
    "#         #x_true, p_true, s_true, s_hat = evaluate_activation(model, dl_house_total[0], a)\n",
    "#         #pm = p_true.sum() / s_true.sum()\n",
    "#         #pm = (ds_appliance[0][APPLIANCE[a]] * \n",
    "#         #      ds_status[0][APPLIANCE[a]]).sum() / ds_status[0][APPLIANCE[a]].sum() / MAX_POWER\n",
    "#         pm = ds_appliance[0][APPLIANCE[a]].sum() / ds_status[0][APPLIANCE[a]].sum() / MAX_POWER\n",
    "#         x_true, p_true, s_true, s_hat = evaluate_activation(model, dl_house_test[0], a)\n",
    "#         s_hat = get_status(s_hat, thr, MIN_OFF[a], MIN_ON[a])\n",
    "#         p_hat = pm * s_hat\n",
    "#         scores[a]['F1'].append(f1_score(s_true, s_hat))\n",
    "#         scores[a]['Precision'].append(precision_score(s_true, s_hat))\n",
    "#         scores[a]['Recall'].append(recall_score(s_true, s_hat))\n",
    "#         scores[a]['Accuracy'].append(accuracy_score(s_true, s_hat))\n",
    "#         scores[a]['MCC'].append(matthews_corrcoef(s_true, s_hat))\n",
    "#         scores[a]['MAE'].append(mean_absolute_error(p_true, p_hat)*MAX_POWER)\n",
    "#         scores[a]['SAE'].append((p_hat.sum() - p_true.sum()) / p_true.sum())\n",
    "\n",
    "# for i,a in enumerate(APPLIANCE):\n",
    "#     print()\n",
    "#     print(a)\n",
    "#     print('F1 score  : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['F1']), sorted(scores[i]['F1'])[1], sorted(scores[i]['F1'])[18]))\n",
    "#     print('Precision : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['Precision']), sorted(scores[i]['Precision'])[1], sorted(scores[i]['Precision'])[18]))\n",
    "#     print('Recall    : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['Recall']), sorted(scores[i]['Recall'])[1], sorted(scores[i]['Recall'])[18]))\n",
    "#     print('Accuracy  : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['Accuracy']), sorted(scores[i]['Accuracy'])[1], sorted(scores[i]['Accuracy'])[18]))\n",
    "#     print('MCC       : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['MCC']), sorted(scores[i]['MCC'])[1], sorted(scores[i]['MCC'])[18]))\n",
    "#     print('MAE       : %.2f (%.2f, %.2f)' %(np.mean(scores[i]['MAE']), sorted(scores[i]['MAE'])[1], sorted(scores[i]['MAE'])[18]))\n",
    "#     print('SAE       : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['SAE']), sorted(scores[i]['SAE'])[1], sorted(scores[i]['SAE'])[18]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "oYjnWxnQyURS",
    "outputId": "1f4f491b-4271-426e-ee56-c739248a2a9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./UKDALE_seen_0.pth\n",
      "./UKDALE_seen_1.pth\n",
      "./UKDALE_seen_2.pth\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 25\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m#x_true, p_true, s_true, s_hat = evaluate_activation(model, dl_house_total[1], a)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m#pm = p_true.sum() / s_true.sum()\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     pm \u001b[38;5;241m=\u001b[39m ds_appliance[\u001b[38;5;241m1\u001b[39m][APPLIANCE[a]]\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m ds_status[\u001b[38;5;241m1\u001b[39m][APPLIANCE[a]]\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m MAX_POWER\n\u001b[1;32m---> 25\u001b[0m     x_true, p_true, s_true, s_hat \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_activation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_house_total\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     s_hat \u001b[38;5;241m=\u001b[39m get_status(s_hat, thr, MIN_OFF[a], MIN_ON[a])\n\u001b[0;32m     27\u001b[0m     p_hat \u001b[38;5;241m=\u001b[39m pm \u001b[38;5;241m*\u001b[39m s_hat\n",
      "Cell \u001b[1;32mIn[21], line 9\u001b[0m, in \u001b[0;36mevaluate_activation\u001b[1;34m(model, loader, a)\u001b[0m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, p, s \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     10\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m         p \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)[:,a,:]\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:317\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    257\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:174\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    171\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:174\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    171\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:223\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\PycharmProjects\\TPNILM\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:214\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    212\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    213\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# unseen results\n",
    "\n",
    "scores = {}\n",
    "for a in range(3):\n",
    "    scores[a] = {}\n",
    "    scores[a]['F1'] = []\n",
    "    scores[a]['Precision'] = []\n",
    "    scores[a]['Recall'] = []\n",
    "    scores[a]['Accuracy'] = []\n",
    "    scores[a]['MCC'] = []\n",
    "    scores[a]['MAE'] = []\n",
    "    scores[a]['SAE'] = []\n",
    "\n",
    "thr = 0.5\n",
    "\n",
    "for i in range(5):\n",
    "    #filename = '/content/gdrive/My Drive/NILM/UKDALE_unseen_%d.pth' %i\n",
    "    filename = './UKDALE_seen_%d.pth' %i\n",
    "    print(filename)\n",
    "    model.load_state_dict(torch.load(filename, weights_only=True))\n",
    "    for a in range(3):\n",
    "        #x_true, p_true, s_true, s_hat = evaluate_activation(model, dl_house_total[1], a)\n",
    "        #pm = p_true.sum() / s_true.sum()\n",
    "        pm = ds_appliance[1][APPLIANCE[a]].sum() / ds_status[1][APPLIANCE[a]].sum() / MAX_POWER\n",
    "        x_true, p_true, s_true, s_hat = evaluate_activation(model, dl_house_total[1], a)\n",
    "        s_hat = get_status(s_hat, thr, MIN_OFF[a], MIN_ON[a])\n",
    "        p_hat = pm * s_hat\n",
    "        scores[a]['F1'].append(f1_score(s_true, s_hat))\n",
    "        scores[a]['Precision'].append(precision_score(s_true, s_hat))\n",
    "        scores[a]['Recall'].append(recall_score(s_true, s_hat))\n",
    "        scores[a]['Accuracy'].append(accuracy_score(s_true, s_hat))\n",
    "        scores[a]['MCC'].append(matthews_corrcoef(s_true, s_hat))\n",
    "        scores[a]['MAE'].append(mean_absolute_error(p_true, p_hat)*MAX_POWER)\n",
    "        scores[a]['SAE'].append((p_hat.sum() - p_true.sum()) / p_true.sum())\n",
    "\n",
    "for i,a in enumerate(APPLIANCE):\n",
    "    print()\n",
    "    print(a)\n",
    "    print('F1 score  : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['F1']), sorted(scores[i]['F1'])[1], sorted(scores[i]['F1'])[18]))\n",
    "    print('Precision : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['Precision']), sorted(scores[i]['Precision'])[1], sorted(scores[i]['Precision'])[18]))\n",
    "    print('Recall    : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['Recall']), sorted(scores[i]['Recall'])[1], sorted(scores[i]['Recall'])[18]))\n",
    "    print('Accuracy  : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['Accuracy']), sorted(scores[i]['Accuracy'])[1], sorted(scores[i]['Accuracy'])[18]))\n",
    "    print('MCC       : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['MCC']), sorted(scores[i]['MCC'])[1], sorted(scores[i]['MCC'])[18]))\n",
    "    print('MAE       : %.2f (%.2f, %.2f)' %(np.mean(scores[i]['MAE']), sorted(scores[i]['MAE'])[1], sorted(scores[i]['MAE'])[18]))\n",
    "    print('SAE       : %.3f (%.3f, %.3f)' %(np.mean(scores[i]['SAE']), sorted(scores[i]['SAE'])[1], sorted(scores[i]['SAE'])[18]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sqLXkeMG3kVJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TPNILM_UKDALE_run.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TPNILM",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
